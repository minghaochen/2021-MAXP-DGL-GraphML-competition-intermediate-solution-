{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "from sklearn.decomposition import PCA\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold,KFold\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.metrics import precision_score\n",
    "from catboost import CatBoostClassifier\n",
    "import dgl\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dgl_graph_k_fold(base_path, fold=-1, k=10, seed=1996):\n",
    "\n",
    "    with open(os.path.join(base_path, 'labels.pkl'), 'rb') as f:\n",
    "        label_data = pickle.load(f)\n",
    "    labels = torch.from_numpy(label_data['label'])\n",
    "    labels = labels.to(torch.int64)\n",
    "    test_label_idx = label_data['test_label_idx']\n",
    "    if fold == -1:\n",
    "        tr_label_idx = label_data['tr_label_idx']\n",
    "        val_label_idx = label_data['val_label_idx']\n",
    "    else:\n",
    "        train_idx = np.concatenate((label_data['tr_label_idx'], label_data['val_label_idx']))\n",
    "        folds = StratifiedKFold(n_splits=k, shuffle=True, random_state=seed)\n",
    "        for i, (tr, val) in enumerate(folds.split(train_idx, labels[train_idx])):\n",
    "            tr_label_idx, val_label_idx = train_idx[tr], train_idx[val]\n",
    "            if i == fold:\n",
    "                print('    ###      use      fold: {}'.format(fold))\n",
    "                break\n",
    "    # get node features\n",
    "    features = np.load(os.path.join(base_path, 'features.npy'))\n",
    "    node_feat = torch.from_numpy(features).float()\n",
    "    print('################ Feature info: ###############')\n",
    "    print('Node\\'s feature shape:{}'.format(node_feat.shape))\n",
    "    return labels, tr_label_idx, val_label_idx, test_label_idx, node_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################ Graph info: ###############\n",
      "Graph(num_nodes=3655452, num_edges=29168650,\n",
      "      ndata_schemes={}\n",
      "      edata_schemes={})\n",
      "load my features torch.Size([3655452, 300])\n"
     ]
    }
   ],
   "source": [
    "base_path = 'DGL'\n",
    "graphs, _ = dgl.load_graphs(os.path.join(base_path, 'graph.bin'))\n",
    "graph = graphs[0]\n",
    "print('################ Graph info: ###############')\n",
    "print(graph)\n",
    "\n",
    "with open(os.path.join(base_path, 'labels.pkl'), 'rb') as f:\n",
    "    label_data = pickle.load(f)\n",
    "\n",
    "labels = torch.from_numpy(label_data['label'])\n",
    "labels = labels.to(torch.int64)\n",
    "tr_label_idx = label_data['tr_label_idx']\n",
    "val_label_idx = label_data['val_label_idx']\n",
    "test_label_idx = label_data['test_label_idx']\n",
    "features = np.load(os.path.join(base_path, 'features.npy'))\n",
    "features = torch.from_numpy(features).float()\n",
    "print(\"load my features\", features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 标签计数\n",
    "labels\n",
    "label_count = []\n",
    "for i in range(23):\n",
    "    nums = (labels == i).sum().numpy().tolist()\n",
    "    label_count.append(nums)\n",
    "# print(label_count/sum(label_count))\n",
    "label_weight = [round(sum(label_count)/i/10) for i in label_count]\n",
    "label_weight = torch.tensor(label_weight).float().to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "degrees = (graph.in_degrees() + graph.out_degrees()).numpy()\n",
    "iso_set = set(np.where(degrees==0)[0])\n",
    "label_nodes = np.array(sorted(list(set(tr_label_idx)|set(val_label_idx))))\n",
    "valid_nodes = np.array(sorted(list(set(label_nodes) & iso_set)))\n",
    "train_nodes = np.array(sorted(list(set(label_nodes) - iso_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FastTensorDataLoader:\n",
    "    def __init__(self, *tensors, batch_size=32, shuffle=False):\n",
    "        assert all(t.shape[0] == tensors[0].shape[0] for t in tensors)\n",
    "        self.tensors = tensors\n",
    "\n",
    "        self.dataset_len = self.tensors[0].shape[0]\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "        # Calculate # batches\n",
    "        n_batches, remainder = divmod(self.dataset_len, self.batch_size)\n",
    "        if remainder > 0:\n",
    "            n_batches += 1\n",
    "        self.n_batches = n_batches\n",
    "    def __iter__(self):\n",
    "        if self.shuffle:\n",
    "            r = torch.randperm(self.dataset_len)\n",
    "            self.tensors = [t[r] for t in self.tensors]\n",
    "        self.i = 0\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.i >= self.dataset_len:\n",
    "            raise StopIteration\n",
    "        batch = tuple(t[self.i:self.i+self.batch_size] for t in self.tensors)\n",
    "        self.i += self.batch_size\n",
    "        return batch\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_batches\n",
    "\n",
    "\n",
    "# batch_size = 4096\n",
    "# train_data_loader = FastTensorDataLoader(\n",
    "#     features[tr_label_idx],\n",
    "#     labels[tr_label_idx],\n",
    "#     batch_size=batch_size, shuffle=True)\n",
    "# valid_data_loader = FastTensorDataLoader(\n",
    "#     features[val_label_idx],\n",
    "#     labels[val_label_idx],\n",
    "#     batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "epsilon = 1 - math.log(2)\n",
    "def custom_loss_function(x, labels, weight = label_weight):\n",
    "    y = F.cross_entropy(x, labels,weight = weight, reduction=\"none\")\n",
    "    y = torch.log(epsilon + y) - math.log(epsilon)\n",
    "    return torch.mean(y)\n",
    "loss_fn = nn.CrossEntropyLoss().to('cuda:0')\n",
    "class ISO_Node_NN(nn.Module):  \n",
    "\n",
    "    def __init__(self): \n",
    "        super(ISO_Node_NN, self).__init__()        \n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(300,2048),\n",
    "            nn.BatchNorm1d(2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(2048,1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(1024,512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512,256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256,128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128,64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(64, 23),\n",
    "        )\n",
    "        \n",
    "\n",
    "    def forward(self, x):  \n",
    "        x = self.net(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# model parameters: 3421463\n",
      "Epoch: 0/100\n",
      "loss_tra 2.052369973970496\n",
      "acc train 0.27717224\n",
      "loss_val 1.818557124871474\n",
      "acc val 0.36816004\n",
      "Epoch: 1/100\n",
      "loss_tra 1.8476709640544393\n",
      "acc train 0.36485133\n",
      "loss_val 1.7328547239303589\n",
      "acc val 0.39682376\n",
      "Epoch: 2/100\n",
      "loss_tra 1.794464930244114\n",
      "acc train 0.38836566\n",
      "loss_val 1.6824805644842296\n",
      "acc val 0.4244952\n",
      "Epoch: 3/100\n",
      "loss_tra 1.7593507694161457\n",
      "acc train 0.40759435\n",
      "loss_val 1.6593025510127728\n",
      "acc val 0.43765703\n",
      "Epoch: 4/100\n",
      "loss_tra 1.7343575757482776\n",
      "acc train 0.4184612\n",
      "loss_val 1.6238491947834308\n",
      "acc val 0.4496862\n",
      "Epoch: 5/100\n",
      "loss_tra 1.6932707174964574\n",
      "acc train 0.43541712\n",
      "loss_val 1.6022444184009845\n",
      "acc val 0.4597008\n",
      "Epoch: 6/100\n",
      "loss_tra 1.6813772854597673\n",
      "acc train 0.4403082\n",
      "loss_val 1.596379422224485\n",
      "acc val 0.46213436\n",
      "Epoch: 7/100\n",
      "loss_tra 1.6789348301680191\n",
      "acc train 0.44102427\n",
      "loss_val 1.5952856586529658\n",
      "acc val 0.46303555\n",
      "Epoch: 8/100\n",
      "loss_tra 1.6803119773450106\n",
      "acc train 0.44088903\n",
      "loss_val 1.596023371586433\n",
      "acc val 0.46177667\n",
      "Epoch: 9/100\n",
      "loss_tra 1.6781377160030864\n",
      "acc train 0.44198608\n",
      "loss_val 1.5901509798490083\n",
      "acc val 0.4636276\n",
      "Epoch: 10/100\n",
      "loss_tra 1.6486506819725038\n",
      "acc train 0.45330372\n",
      "loss_val 1.570038112310263\n",
      "acc val 0.4729117\n",
      "Epoch: 11/100\n",
      "loss_tra 1.6359932277513587\n",
      "acc train 0.45839924\n",
      "loss_val 1.565198233494392\n",
      "acc val 0.47415978\n",
      "Epoch: 12/100\n",
      "loss_tra 1.6361414655395177\n",
      "acc train 0.45799512\n",
      "loss_val 1.5682044258484473\n",
      "acc val 0.47283632\n",
      "Epoch: 13/100\n",
      "loss_tra 1.6406828895859096\n",
      "acc train 0.45704406\n",
      "loss_val 1.5718228633587177\n",
      "acc val 0.47141907\n",
      "Epoch: 14/100\n",
      "loss_tra 1.6466366762700289\n",
      "acc train 0.45434424\n",
      "loss_val 1.5776379291827862\n",
      "acc val 0.46912703\n",
      "Epoch: 15/100\n",
      "loss_tra 1.6191261602484661\n",
      "acc train 0.46488827\n",
      "loss_val 1.5589711391008818\n",
      "acc val 0.4768103\n",
      "Epoch: 16/100\n",
      "loss_tra 1.6074030554812888\n",
      "acc train 0.46973518\n",
      "loss_val 1.5562255795185382\n",
      "acc val 0.47867647\n",
      "Epoch: 17/100\n",
      "loss_tra 1.6095812419186468\n",
      "acc train 0.4690864\n",
      "loss_val 1.560297415806697\n",
      "acc val 0.4771387\n",
      "Epoch: 18/100\n",
      "loss_tra 1.6155708214511042\n",
      "acc train 0.46649295\n",
      "loss_val 1.56192841896644\n",
      "acc val 0.4766501\n",
      "Epoch: 19/100\n",
      "loss_tra 1.623714572450389\n",
      "acc train 0.46348464\n",
      "loss_val 1.5714811315903296\n",
      "acc val 0.47351462\n",
      "Epoch: 20/100\n",
      "loss_tra 1.5972303063973137\n",
      "acc train 0.47392988\n",
      "loss_val 1.5542279665286725\n",
      "acc val 0.48018938\n",
      "Epoch: 21/100\n",
      "loss_tra 1.588391546062801\n",
      "acc train 0.4776411\n",
      "loss_val 1.5493337374467115\n",
      "acc val 0.4813439\n",
      "Epoch: 22/100\n",
      "loss_tra 1.5885901482208915\n",
      "acc train 0.47724\n",
      "loss_val 1.5529561317884004\n",
      "acc val 0.4807248\n",
      "Epoch: 23/100\n",
      "loss_tra 1.5949854653814564\n",
      "acc train 0.47482407\n",
      "loss_val 1.5598521691102247\n",
      "acc val 0.4781163\n",
      "Epoch: 24/100\n",
      "loss_tra 1.6035942782526431\n",
      "acc train 0.4716422\n",
      "loss_val 1.5655240003879254\n",
      "acc val 0.47419068\n",
      "Epoch: 25/100\n",
      "loss_tra 1.5808396484540856\n",
      "acc train 0.48036334\n",
      "loss_val 1.5470655193695655\n",
      "acc val 0.4828486\n",
      "Epoch: 26/100\n",
      "loss_tra 1.5715603087259375\n",
      "acc train 0.48404786\n",
      "loss_val 1.5424870756956248\n",
      "acc val 0.48418763\n",
      "Epoch: 27/100\n",
      "loss_tra 1.5720485490301381\n",
      "acc train 0.483487\n",
      "loss_val 1.543644877580496\n",
      "acc val 0.48389676\n",
      "Epoch: 28/100\n",
      "loss_tra 1.5791242780892745\n",
      "acc train 0.48081994\n",
      "loss_val 1.5512141356101403\n",
      "acc val 0.4815981\n",
      "Epoch: 29/100\n",
      "loss_tra 1.5876498901325724\n",
      "acc train 0.47790447\n",
      "loss_val 1.5574339444820697\n",
      "acc val 0.47884706\n",
      "Epoch: 30/100\n",
      "loss_tra 1.5675687085027281\n",
      "acc train 0.4854075\n",
      "loss_val 1.541121469094203\n",
      "acc val 0.48503193\n",
      "Epoch: 31/100\n",
      "loss_tra 1.5574075279028519\n",
      "acc train 0.48947963\n",
      "loss_val 1.54335467173503\n",
      "acc val 0.48338288\n",
      "Epoch: 32/100\n",
      "loss_tra 1.5599620596222254\n",
      "acc train 0.48840508\n",
      "loss_val 1.547723582157722\n",
      "acc val 0.48286453\n",
      "Epoch: 33/100\n",
      "loss_tra 1.5653654658276102\n",
      "acc train 0.48647672\n",
      "loss_val 1.5478282020642207\n",
      "acc val 0.48205698\n",
      "Epoch: 34/100\n",
      "loss_tra 1.5751768594202789\n",
      "acc train 0.48261034\n",
      "loss_val 1.5555169903315031\n",
      "acc val 0.48042646\n",
      "Epoch: 35/100\n",
      "loss_tra 1.5560718168383059\n",
      "acc train 0.4899856\n",
      "loss_val 1.5421424691493695\n",
      "acc val 0.48545772\n",
      "Epoch: 36/100\n",
      "loss_tra 1.5451618790626527\n",
      "acc train 0.49410835\n",
      "loss_val 1.5437133587323701\n",
      "acc val 0.48516652\n",
      "Epoch: 37/100\n",
      "loss_tra 1.5468364238739014\n",
      "acc train 0.4934906\n",
      "loss_val 1.5415686689890349\n",
      "acc val 0.48574793\n",
      "Epoch: 38/100\n",
      "loss_tra 1.5539134429848713\n",
      "acc train 0.4909714\n",
      "loss_val 1.5460375868357146\n",
      "acc val 0.48314616\n",
      "Epoch: 39/100\n",
      "loss_tra 1.5654614090919494\n",
      "acc train 0.48672804\n",
      "loss_val 1.5498747825622559\n",
      "acc val 0.48290235\n",
      "Epoch: 40/100\n",
      "loss_tra 1.5442135245903679\n",
      "acc train 0.49472862\n",
      "loss_val 1.539943121946775\n",
      "acc val 0.48725113\n",
      "Epoch: 41/100\n",
      "loss_tra 1.5350406900696132\n",
      "acc train 0.4980399\n",
      "loss_val 1.541365453830132\n",
      "acc val 0.48626515\n",
      "Epoch: 42/100\n",
      "loss_tra 1.5367364992266115\n",
      "acc train 0.49714854\n",
      "loss_val 1.5392664533395033\n",
      "acc val 0.48724726\n",
      "Epoch: 43/100\n",
      "loss_tra 1.5447043050890383\n",
      "acc train 0.49435392\n",
      "loss_val 1.542558605854328\n",
      "acc val 0.48495\n",
      "Epoch: 44/100\n",
      "loss_tra 1.5538593862367713\n",
      "acc train 0.49090487\n",
      "loss_val 1.5471700567465563\n",
      "acc val 0.4831258\n",
      "Epoch: 45/100\n",
      "loss_tra 1.5346169575400974\n",
      "acc train 0.49819025\n",
      "loss_val 1.536068361539107\n",
      "acc val 0.48790517\n",
      "Epoch: 46/100\n",
      "loss_tra 1.5249881827312968\n",
      "acc train 0.50215733\n",
      "loss_val 1.5433227740801299\n",
      "acc val 0.4860209\n",
      "Epoch: 47/100\n",
      "loss_tra 1.5277512508889903\n",
      "acc train 0.5012017\n",
      "loss_val 1.5383523381673372\n",
      "acc val 0.4881053\n",
      "Epoch: 48/100\n",
      "loss_tra 1.5362227564272672\n",
      "acc train 0.49784154\n",
      "loss_val 1.5393000199244573\n",
      "acc val 0.4867784\n",
      "Epoch: 49/100\n",
      "loss_tra 1.5460487267245417\n",
      "acc train 0.4943378\n",
      "loss_val 1.5446208944687476\n",
      "acc val 0.48487252\n",
      "Epoch: 50/100\n",
      "loss_tra 1.5267082224721493\n",
      "acc train 0.5013617\n",
      "loss_val 1.5340459163372333\n",
      "acc val 0.48898473\n",
      "Epoch: 51/100\n",
      "loss_tra 1.5173424036606498\n",
      "acc train 0.50482\n",
      "loss_val 1.5347678248698895\n",
      "acc val 0.489268\n",
      "Epoch: 52/100\n",
      "loss_tra 1.519274311998616\n",
      "acc train 0.504401\n",
      "loss_val 1.5366138311532826\n",
      "acc val 0.48868433\n",
      "Epoch: 53/100\n",
      "loss_tra 1.527049405678459\n",
      "acc train 0.5015202\n",
      "loss_val 1.5404672897779024\n",
      "acc val 0.48707348\n",
      "Epoch: 54/100\n",
      "loss_tra 1.5378704340561578\n",
      "acc train 0.49777508\n",
      "loss_val 1.5402136628444378\n",
      "acc val 0.48656365\n",
      "Epoch: 55/100\n",
      "loss_tra 1.5179785479669985\n",
      "acc train 0.5047337\n",
      "loss_val 1.534764642898853\n",
      "acc val 0.48930377\n",
      "Epoch: 56/100\n",
      "loss_tra 1.5098062105800794\n",
      "acc train 0.50807774\n",
      "loss_val 1.5342764716881971\n",
      "acc val 0.48893073\n",
      "Epoch: 57/100\n",
      "loss_tra 1.5119805838750757\n",
      "acc train 0.5074095\n",
      "loss_val 1.5385849292461689\n",
      "acc val 0.4868935\n",
      "Epoch: 58/100\n",
      "loss_tra 1.5204540905745134\n",
      "acc train 0.5043468\n",
      "loss_val 1.5418724234287555\n",
      "acc val 0.48678988\n",
      "Epoch: 59/100\n",
      "loss_tra 1.5293880758078202\n",
      "acc train 0.5009165\n",
      "loss_val 1.5453030329484205\n",
      "acc val 0.48459354\n",
      "Epoch: 60/100\n",
      "loss_tra 1.5123024100842684\n",
      "acc train 0.50715494\n",
      "loss_val 1.5360662432817311\n",
      "acc val 0.48854446\n",
      "Epoch: 61/100\n",
      "loss_tra 1.50295018631479\n",
      "acc train 0.5105194\n",
      "loss_val 1.5325863223809462\n",
      "acc val 0.4898313\n",
      "Epoch: 62/100\n",
      "loss_tra 1.5053802453953287\n",
      "acc train 0.50999725\n",
      "loss_val 1.5346762721355145\n",
      "acc val 0.48980266\n",
      "Epoch: 63/100\n",
      "loss_tra 1.5139987137006676\n",
      "acc train 0.50664085\n",
      "loss_val 1.5374490847954383\n",
      "acc val 0.48769048\n",
      "Epoch: 64/100\n",
      "loss_tra 1.5227574405462845\n",
      "acc train 0.5034483\n",
      "loss_val 1.5462027467214143\n",
      "acc val 0.4851637\n",
      "Epoch: 65/100\n",
      "loss_tra 1.5045417469480764\n",
      "acc train 0.51023436\n",
      "loss_val 1.534152553631709\n",
      "acc val 0.48909038\n",
      "Epoch: 66/100\n",
      "loss_tra 1.496668032977892\n",
      "acc train 0.5132209\n",
      "loss_val 1.5365951382196867\n",
      "acc val 0.49052605\n",
      "Epoch: 67/100\n",
      "loss_tra 1.4993212995321854\n",
      "acc train 0.5124225\n",
      "loss_val 1.5310935561473553\n",
      "acc val 0.48984817\n",
      "Epoch: 68/100\n",
      "loss_tra 1.5063548741133317\n",
      "acc train 0.5097048\n",
      "loss_val 1.5363355049720178\n",
      "acc val 0.48880002\n",
      "Epoch: 69/100\n",
      "loss_tra 1.516841238996257\n",
      "acc train 0.50572616\n",
      "loss_val 1.547488822386815\n",
      "acc val 0.4850734\n",
      "Epoch: 70/100\n",
      "loss_tra 1.4988546355910923\n",
      "acc train 0.51273733\n",
      "loss_val 1.5372484372212336\n",
      "acc val 0.48861203\n",
      "Epoch: 71/100\n",
      "loss_tra 1.4904768337374148\n",
      "acc train 0.51561487\n",
      "loss_val 1.5327858649767363\n",
      "acc val 0.48925006\n",
      "Epoch: 72/100\n",
      "loss_tra 1.4939558210580246\n",
      "acc train 0.5139902\n",
      "loss_val 1.5362756527387178\n",
      "acc val 0.4890632\n",
      "Epoch: 73/100\n",
      "loss_tra 1.5005040168762207\n",
      "acc train 0.51174444\n",
      "loss_val 1.538093557724586\n",
      "acc val 0.4895137\n",
      "Epoch: 74/100\n",
      "loss_tra 1.508998161295186\n",
      "acc train 0.5086822\n",
      "loss_val 1.5378907781380873\n",
      "acc val 0.48740035\n",
      "Epoch: 75/100\n",
      "loss_tra 1.494123617980791\n",
      "acc train 0.5139578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_val 1.5355803278776317\n",
      "acc val 0.48958826\n",
      "Epoch: 76/100\n",
      "loss_tra 1.4862859015879424\n",
      "acc train 0.51753914\n",
      "loss_val 1.5322434122745807\n",
      "acc val 0.49026197\n",
      "Epoch: 77/100\n",
      "loss_tra 1.4867913075115369\n",
      "acc train 0.51700896\n",
      "loss_val 1.5337762924341054\n",
      "acc val 0.48923144\n",
      "Epoch: 78/100\n",
      "loss_tra 1.4958724104839822\n",
      "acc train 0.51378065\n",
      "loss_val 1.534531859251169\n",
      "acc val 0.48904327\n",
      "Epoch: 79/100\n",
      "loss_tra 1.504378642724908\n",
      "acc train 0.51064825\n",
      "loss_val 1.5398644759104803\n",
      "acc val 0.48756167\n",
      "Epoch: 80/100\n",
      "loss_tra 1.4886443656423818\n",
      "acc train 0.5165693\n",
      "loss_val 1.5326617772762592\n",
      "acc val 0.4899357\n",
      "Epoch: 81/100\n",
      "loss_tra 1.4803277689477672\n",
      "acc train 0.5196534\n",
      "loss_val 1.5328511916674101\n",
      "acc val 0.4905736\n",
      "Epoch: 82/100\n",
      "loss_tra 1.4824963030607805\n",
      "acc train 0.5188248\n",
      "loss_val 1.5289457577925463\n",
      "acc val 0.49155837\n",
      "Epoch: 83/100\n",
      "loss_tra 1.4901759790337603\n",
      "acc train 0.5158355\n",
      "loss_val 1.534073068545415\n",
      "acc val 0.48893884\n",
      "Epoch: 84/100\n",
      "loss_tra 1.5000636520593063\n",
      "acc train 0.512388\n",
      "loss_val 1.538420475446261\n",
      "acc val 0.48757613\n",
      "Epoch: 85/100\n",
      "loss_tra 1.4841344719347747\n",
      "acc train 0.51831996\n",
      "loss_val 1.535998523235321\n",
      "acc val 0.4907322\n",
      "Epoch: 86/100\n",
      "loss_tra 1.4756976816965186\n",
      "acc train 0.5211978\n",
      "loss_val 1.5320686468711266\n",
      "acc val 0.4907356\n",
      "Epoch: 87/100\n",
      "loss_tra 1.476903954277868\n",
      "acc train 0.52091855\n",
      "loss_val 1.533848423224229\n",
      "acc val 0.48978376\n",
      "Epoch: 88/100\n",
      "loss_tra 1.4845281606135161\n",
      "acc train 0.51837915\n",
      "loss_val 1.5399670830139747\n",
      "acc val 0.48812294\n",
      "Epoch: 89/100\n",
      "loss_tra 1.4953365590261376\n",
      "acc train 0.5142324\n",
      "loss_val 1.5367859189326947\n",
      "acc val 0.4888271\n",
      "Epoch: 90/100\n",
      "loss_tra 1.4780556709870047\n",
      "acc train 0.5204424\n",
      "loss_val 1.5337650913458605\n",
      "acc val 0.49048126\n",
      "Epoch: 91/100\n",
      "loss_tra 1.4705212131790493\n",
      "acc train 0.52330554\n",
      "loss_val 1.5324231890531688\n",
      "acc val 0.49028322\n",
      "Epoch: 92/100\n",
      "loss_tra 1.4734976991363193\n",
      "acc train 0.5224896\n",
      "loss_val 1.534308318908398\n",
      "acc val 0.4901408\n",
      "Epoch: 93/100\n",
      "loss_tra 1.4810062460277391\n",
      "acc train 0.51955104\n",
      "loss_val 1.5371938852163463\n",
      "acc val 0.48967254\n",
      "Epoch: 94/100\n",
      "loss_tra 1.4893230578173762\n",
      "acc train 0.51661026\n",
      "loss_val 1.5384860680653498\n",
      "acc val 0.4887423\n",
      "Epoch: 95/100\n",
      "loss_tra 1.4750071919482688\n",
      "acc train 0.52164984\n",
      "loss_val 1.5323722866865306\n",
      "acc val 0.49111813\n",
      "Epoch: 96/100\n",
      "loss_tra 1.4674439860426862\n",
      "acc train 0.5246874\n",
      "loss_val 1.5312080795948322\n",
      "acc val 0.49152246\n",
      "Epoch: 97/100\n",
      "loss_tra 1.4680613206780475\n",
      "acc train 0.5240424\n",
      "loss_val 1.5337720467494085\n",
      "acc val 0.49126893\n"
     ]
    }
   ],
   "source": [
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group[\"lr\"] = 0.001 + (epoch % 5)*0.001\n",
    "\n",
    "n_epochs = 100\n",
    "device = 'cuda:0'\n",
    "model = ISO_Node_NN().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0003, weight_decay=0)\n",
    "print('# model parameters:', sum(param.numel() for param in model.parameters()))\n",
    "\n",
    "\n",
    "loss_tra = []\n",
    "loss_val = []\n",
    "val_best = 1e9\n",
    "stop_count = 0\n",
    "for epoch in range(n_epochs):\n",
    "    adjust_learning_rate(optimizer, epoch)\n",
    "    model.train()\n",
    "    epoch_loss = []\n",
    "    c = 0\n",
    "    print(\"Epoch: {}/{}\".format(epoch, n_epochs))\n",
    "    val_acc_list = []\n",
    "    for X_sequence, target in train_data_loader:\n",
    "        X_sequence, target = X_sequence.to(device), target.to(device)\n",
    "\n",
    "        y_hat = model(X_sequence)\n",
    "        train_loss = custom_loss_function(y_hat, target)\n",
    "        \n",
    "        val_batch_pred = torch.sum(torch.argmax(y_hat, dim=1) == target) / torch.tensor(target.shape[0])\n",
    "        val_acc_list.append(val_batch_pred.detach().cpu().numpy())\n",
    "\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        epoch_loss.append(train_loss.item())\n",
    "    loss_tra = np.mean(epoch_loss)\n",
    "    print('loss_tra',loss_tra)\n",
    "    print('acc train',np.mean(val_acc_list))\n",
    "\n",
    "    # 验证集\n",
    "    model.eval()\n",
    "    epoch_loss = []\n",
    "    val_acc_list = []\n",
    "    for X_sequence, target in valid_data_loader:\n",
    "        X_sequence, target = X_sequence.to(device), target.to(device)\n",
    "        y_hat = model(X_sequence)\n",
    "        valid_loss = custom_loss_function(y_hat, target)\n",
    "        epoch_loss.append(valid_loss.item())\n",
    "\n",
    "        val_batch_pred = torch.sum(torch.argmax(y_hat, dim=1) == target) / torch.tensor(target.shape[0])\n",
    "        val_acc_list.append(val_batch_pred.detach().cpu().numpy())\n",
    "\n",
    "\n",
    "    loss_val = np.mean(epoch_loss)\n",
    "    print('loss_val',loss_val)\n",
    "    print('acc val',np.mean(val_acc_list))\n",
    "    if loss_val < val_best:\n",
    "        val_best = loss_val\n",
    "        acc_best = np.mean(val_acc_list)\n",
    "        stop_count = 0\n",
    "        best_model = deepcopy(model)\n",
    "    else:\n",
    "        stop_count += 1\n",
    "    if stop_count == 15:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ###      use      fold: 0\n",
      "################ Feature info: ###############\n",
      "Node's feature shape:torch.Size([3655452, 300])\n",
      "# model parameters: 3421463\n",
      "Epoch: 0/1000\n",
      "loss_tra 2.6028304265893025\n",
      "acc train 0.26846093\n",
      "loss_val 2.334945412782522\n",
      "acc val 0.36126423\n",
      "Epoch: 1/1000\n",
      "loss_tra 2.3465975637021272\n",
      "acc train 0.36054435\n",
      "loss_val 2.2191563844680786\n",
      "acc val 0.39478192\n",
      "Epoch: 2/1000\n",
      "loss_tra 2.2715879492137745\n",
      "acc train 0.38586035\n",
      "loss_val 2.146085739135742\n",
      "acc val 0.41429976\n",
      "Epoch: 3/1000\n",
      "loss_tra 2.2163031671358193\n",
      "acc train 0.40666592\n",
      "loss_val 2.091152686339158\n",
      "acc val 0.43063927\n",
      "Epoch: 4/1000\n",
      "loss_tra 2.183532497157221\n",
      "acc train 0.41815066\n",
      "loss_val 2.073611772977389\n",
      "acc val 0.43656415\n",
      "Epoch: 5/1000\n",
      "loss_tra 2.1333184802013894\n",
      "acc train 0.43409935\n",
      "loss_val 2.033166087590731\n",
      "acc val 0.44918826\n",
      "Epoch: 6/1000\n",
      "loss_tra 2.1162938128346984\n",
      "acc train 0.43889803\n",
      "loss_val 2.0299762670810404\n",
      "acc val 0.45150545\n",
      "Epoch: 7/1000\n",
      "loss_tra 2.112400432254957\n",
      "acc train 0.4400709\n",
      "loss_val 2.0200928633029642\n",
      "acc val 0.45352507\n",
      "Epoch: 10/1000\n",
      "loss_tra 2.0732439466144728\n",
      "acc train 0.45268303\n",
      "loss_val 1.9960466348207915\n",
      "acc val 0.46030596\n",
      "Epoch: 11/1000\n",
      "loss_tra 2.05787508332211\n",
      "acc train 0.4573337\n",
      "loss_val 1.9947656668149507\n",
      "acc val 0.46138272\n",
      "Epoch: 12/1000\n",
      "loss_tra 2.058894155854764\n",
      "acc train 0.45702887\n",
      "loss_val 1.994538357624641\n",
      "acc val 0.46060413\n",
      "Epoch: 15/1000\n",
      "loss_tra 2.0372909364492995\n",
      "acc train 0.46306202\n",
      "loss_val 1.9852666579760039\n",
      "acc val 0.4647066\n",
      "Epoch: 16/1000\n",
      "loss_tra 2.021292951314346\n",
      "acc train 0.46837884\n",
      "loss_val 1.9780450554994435\n",
      "acc val 0.46623945\n",
      "Epoch: 20/1000\n",
      "loss_tra 2.011557083544524\n",
      "acc train 0.47117934\n",
      "loss_val 1.9726349436319792\n",
      "acc val 0.46934736\n",
      "Epoch: 21/1000\n",
      "loss_tra 1.9968870152597842\n",
      "acc train 0.47607166\n",
      "loss_val 1.9689359664916992\n",
      "acc val 0.4711859\n",
      "Epoch: 25/1000\n",
      "loss_tra 1.9899051261984784\n",
      "acc train 0.4781386\n",
      "loss_val 1.9644078887425935\n",
      "acc val 0.47205156\n",
      "Epoch: 26/1000\n",
      "loss_tra 1.976045126500337\n",
      "acc train 0.48193413\n",
      "loss_val 1.9627032050719628\n",
      "acc val 0.47212756\n",
      "Epoch: 30/1000\n",
      "loss_tra 1.9736664523249088\n",
      "acc train 0.48277786\n",
      "loss_val 1.9603584867257338\n",
      "acc val 0.4733393\n",
      "Epoch: 31/1000\n",
      "loss_tra 1.9607485040374424\n",
      "acc train 0.4868084\n",
      "loss_val 1.9585500130286584\n",
      "acc val 0.4741855\n",
      "Epoch: 36/1000\n",
      "loss_tra 1.9446962501691736\n",
      "acc train 0.4915014\n",
      "loss_val 1.9571489691734314\n",
      "acc val 0.47476736\n",
      "Epoch: 41/1000\n",
      "loss_tra 1.9347508715546649\n",
      "acc train 0.4947795\n",
      "loss_val 1.9550556402940016\n",
      "acc val 0.4758573\n",
      "Epoch: 45/1000\n",
      "loss_tra 1.9357470020003942\n",
      "acc train 0.49415764\n",
      "loss_val 1.954099292938526\n",
      "acc val 0.47611687\n",
      "Epoch: 51/1000\n",
      "loss_tra 1.9125250883724378\n",
      "acc train 0.50096214\n",
      "loss_val 1.952721384855417\n",
      "acc val 0.47723913\n",
      "Epoch: 55/1000\n",
      "loss_tra 1.9167463706887287\n",
      "acc train 0.49979657\n",
      "loss_val 1.949820523078625\n",
      "acc val 0.47848737\n",
      "Epoch: 65/1000\n",
      "loss_tra 1.8967477119487264\n",
      "acc train 0.5056219\n",
      "loss_val 1.9493534794220557\n",
      "acc val 0.47867343\n",
      "Epoch: 72/1000\n",
      "loss_tra 1.8818747748499332\n",
      "acc train 0.5103453\n",
      "loss_val 1.9475882695271418\n",
      "acc val 0.47904018\n",
      "Epoch: 76/1000\n",
      "loss_tra 1.8734130351439766\n",
      "acc train 0.5126634\n",
      "loss_val 1.9470251019184406\n",
      "acc val 0.4801577\n",
      "Epoch: 77/1000\n",
      "loss_tra 1.8752393841743469\n",
      "acc train 0.511806\n",
      "loss_val 1.9465111218965971\n",
      "acc val 0.47975194\n",
      "Epoch: 81/1000\n",
      "loss_tra 1.8679470233295274\n",
      "acc train 0.5143595\n",
      "loss_val 1.9452766867784352\n",
      "acc val 0.48034447\n",
      "val_best 0.48034447\n",
      "    ###      use      fold: 1\n",
      "################ Feature info: ###############\n",
      "Node's feature shape:torch.Size([3655452, 300])\n",
      "# model parameters: 3421463\n",
      "Epoch: 0/1000\n",
      "loss_tra 2.593518577451291\n",
      "acc train 0.27167282\n",
      "loss_val 2.344347752057589\n",
      "acc val 0.35409948\n",
      "Epoch: 1/1000\n",
      "loss_tra 2.3515578477279\n",
      "acc train 0.36112446\n",
      "loss_val 2.201204437475938\n",
      "acc val 0.39663997\n",
      "Epoch: 2/1000\n",
      "loss_tra 2.2678434734759123\n",
      "acc train 0.3871486\n",
      "loss_val 2.1310638097616343\n",
      "acc val 0.41859853\n",
      "Epoch: 3/1000\n",
      "loss_tra 2.214368879276773\n",
      "acc train 0.4071944\n",
      "loss_val 2.089574392025287\n",
      "acc val 0.4322704\n",
      "Epoch: 4/1000\n",
      "loss_tra 2.1837604190992272\n",
      "acc train 0.41802323\n",
      "loss_val 2.071840222065265\n",
      "acc val 0.43826473\n",
      "Epoch: 5/1000\n",
      "loss_tra 2.132219676349474\n",
      "acc train 0.43411046\n",
      "loss_val 2.037552751027621\n",
      "acc val 0.44925073\n",
      "Epoch: 6/1000\n",
      "loss_tra 2.1157753913298896\n",
      "acc train 0.43929815\n",
      "loss_val 2.029947354243352\n",
      "acc val 0.45051858\n",
      "Epoch: 8/1000\n",
      "loss_tra 2.1121362043463665\n",
      "acc train 0.44046086\n",
      "loss_val 2.0266582048856296\n",
      "acc val 0.45244518\n",
      "Epoch: 9/1000\n",
      "loss_tra 2.1094751917797585\n",
      "acc train 0.44124857\n",
      "loss_val 2.0224464398164015\n",
      "acc val 0.45305446\n",
      "Epoch: 10/1000\n",
      "loss_tra 2.0709067199541176\n",
      "acc train 0.45289394\n",
      "loss_val 2.001240977874169\n",
      "acc val 0.45984185\n",
      "Epoch: 11/1000\n",
      "loss_tra 2.057249847702358\n",
      "acc train 0.45730633\n",
      "loss_val 1.998152155142564\n",
      "acc val 0.4617035\n",
      "Epoch: 15/1000\n",
      "loss_tra 2.0356473300767983\n",
      "acc train 0.4635774\n",
      "loss_val 1.9839287079297578\n",
      "acc val 0.46549785\n",
      "Epoch: 16/1000\n",
      "loss_tra 2.0217536646386853\n",
      "acc train 0.46785754\n",
      "loss_val 1.980357798246237\n",
      "acc val 0.4677896\n",
      "Epoch: 20/1000\n",
      "loss_tra 2.008857320184293\n",
      "acc train 0.47179207\n",
      "loss_val 1.9775071740150452\n",
      "acc val 0.4689533\n",
      "Epoch: 21/1000\n",
      "loss_tra 1.9969724173131196\n",
      "acc train 0.47581676\n",
      "loss_val 1.9729085610463069\n",
      "acc val 0.4700972\n",
      "Epoch: 25/1000\n",
      "loss_tra 1.9879619256309842\n",
      "acc train 0.47828746\n",
      "loss_val 1.9713045863004832\n",
      "acc val 0.47074577\n",
      "Epoch: 26/1000\n",
      "loss_tra 1.9745616689972256\n",
      "acc train 0.4821616\n",
      "loss_val 1.9669116231111379\n",
      "acc val 0.47210118\n",
      "Epoch: 30/1000\n",
      "loss_tra 1.972003962682641\n",
      "acc train 0.48293164\n",
      "loss_val 1.9647543384478643\n",
      "acc val 0.47251385\n",
      "Epoch: 31/1000\n",
      "loss_tra 1.9594668004823768\n",
      "acc train 0.4866958\n",
      "loss_val 1.9632592247082636\n",
      "acc val 0.47258765\n",
      "Epoch: 40/1000\n",
      "loss_tra 1.944428563117981\n",
      "acc train 0.49142018\n",
      "loss_val 1.9612406217134917\n",
      "acc val 0.47406238\n",
      "Epoch: 41/1000\n",
      "loss_tra 1.9327472448349\n",
      "acc train 0.49475828\n",
      "loss_val 1.9587367910605211\n",
      "acc val 0.4755381\n",
      "Epoch: 46/1000\n",
      "loss_tra 1.9225948230079983\n",
      "acc train 0.49811673\n",
      "loss_val 1.9585631810701811\n",
      "acc val 0.4753036\n",
      "Epoch: 51/1000\n",
      "loss_tra 1.9114625013392905\n",
      "acc train 0.5013713\n",
      "loss_val 1.957155397305122\n",
      "acc val 0.4756114\n",
      "Epoch: 65/1000\n",
      "loss_tra 1.9006339404893957\n",
      "acc train 0.50412697\n",
      "loss_val 1.9566382078024058\n",
      "acc val 0.47693747\n",
      "Epoch: 67/1000\n",
      "loss_tra 1.8882626751194829\n",
      "acc train 0.50812227\n",
      "loss_val 1.956444685275738\n",
      "acc val 0.47680575\n",
      "Epoch: 75/1000\n",
      "loss_tra 1.8838398570599764\n",
      "acc train 0.5094651\n",
      "loss_val 1.9554646565363958\n",
      "acc val 0.4778948\n",
      "Epoch: 81/1000\n",
      "loss_tra 1.866579872628917\n",
      "acc train 0.5144543\n",
      "loss_val 1.9553198172495916\n",
      "acc val 0.4779414\n",
      "Epoch: 90/1000\n",
      "loss_tra 1.865823413496432\n",
      "acc train 0.51451147\n",
      "loss_val 1.9518300203176646\n",
      "acc val 0.47826046\n",
      "val_best 0.47826046\n",
      "    ###      use      fold: 2\n",
      "################ Feature info: ###############\n",
      "Node's feature shape:torch.Size([3655452, 300])\n",
      "# model parameters: 3421463\n",
      "Epoch: 0/1000\n",
      "loss_tra 2.587998104095459\n",
      "acc train 0.27567723\n",
      "loss_val 2.3433645963668823\n",
      "acc val 0.35555643\n",
      "Epoch: 1/1000\n",
      "loss_tra 2.3560463594353718\n",
      "acc train 0.36049393\n",
      "loss_val 2.2195389087383566\n",
      "acc val 0.39358032\n",
      "Epoch: 2/1000\n",
      "loss_tra 2.2716953972111575\n",
      "acc train 0.3864005\n",
      "loss_val 2.1566582367970395\n",
      "acc val 0.41549858\n",
      "Epoch: 3/1000\n",
      "loss_tra 2.2175367552301157\n",
      "acc train 0.4069852\n",
      "loss_val 2.093314400086036\n",
      "acc val 0.43233526\n",
      "Epoch: 4/1000\n",
      "loss_tra 2.182697565659233\n",
      "acc train 0.41890723\n",
      "loss_val 2.0700742648198056\n",
      "acc val 0.4389214\n",
      "Epoch: 5/1000\n",
      "loss_tra 2.1329150313916414\n",
      "acc train 0.4346657\n",
      "loss_val 2.041476011276245\n",
      "acc val 0.44758764\n",
      "Epoch: 6/1000\n",
      "loss_tra 2.1149403540984446\n",
      "acc train 0.44020638\n",
      "loss_val 2.029408785013052\n",
      "acc val 0.4509884\n",
      "Epoch: 7/1000\n",
      "loss_tra 2.1126093004060826\n",
      "acc train 0.44101667\n",
      "loss_val 2.0291283314044657\n",
      "acc val 0.45009533\n",
      "Epoch: 8/1000\n",
      "loss_tra 2.1111267400824505\n",
      "acc train 0.44110844\n",
      "loss_val 2.026483728335454\n",
      "acc val 0.45059314\n",
      "Epoch: 10/1000\n",
      "loss_tra 2.0724338158317233\n",
      "acc train 0.4531104\n",
      "loss_val 2.002884961091555\n",
      "acc val 0.4598157\n",
      "Epoch: 11/1000\n",
      "loss_tra 2.0569797443306963\n",
      "acc train 0.45779803\n",
      "loss_val 2.000061346934392\n",
      "acc val 0.4608091\n",
      "Epoch: 12/1000\n",
      "loss_tra 2.057469601734825\n",
      "acc train 0.45724553\n",
      "loss_val 1.9992391191996062\n",
      "acc val 0.46023846\n",
      "Epoch: 15/1000\n",
      "loss_tra 2.038998458178147\n",
      "acc train 0.46273404\n",
      "loss_val 1.988612399651454\n",
      "acc val 0.46445352\n",
      "Epoch: 16/1000\n",
      "loss_tra 2.0240547252737957\n",
      "acc train 0.4671954\n",
      "loss_val 1.9855638329799359\n",
      "acc val 0.4653363\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20/1000\n",
      "loss_tra 2.0137831138527913\n",
      "acc train 0.47029418\n",
      "loss_val 1.9813633469434886\n",
      "acc val 0.46666923\n",
      "Epoch: 21/1000\n",
      "loss_tra 2.000029044565947\n",
      "acc train 0.47458845\n",
      "loss_val 1.9764696863981395\n",
      "acc val 0.46800324\n",
      "Epoch: 25/1000\n",
      "loss_tra 1.9928881318672844\n",
      "acc train 0.4770874\n",
      "loss_val 1.9740115725077116\n",
      "acc val 0.46968442\n",
      "Epoch: 26/1000\n",
      "loss_tra 1.9785069087277287\n",
      "acc train 0.4810633\n",
      "loss_val 1.9696663618087769\n",
      "acc val 0.47032458\n",
      "Epoch: 31/1000\n",
      "loss_tra 1.962324627586033\n",
      "acc train 0.48591232\n",
      "loss_val 1.9680878153214088\n",
      "acc val 0.4717303\n",
      "Epoch: 32/1000\n",
      "loss_tra 1.964816515342049\n",
      "acc train 0.4853598\n",
      "loss_val 1.9675668386312632\n",
      "acc val 0.47113153\n",
      "Epoch: 35/1000\n",
      "loss_tra 1.9609842953474625\n",
      "acc train 0.486428\n",
      "loss_val 1.9670148812807524\n",
      "acc val 0.47173113\n",
      "Epoch: 36/1000\n",
      "loss_tra 1.9483164890952733\n",
      "acc train 0.48991573\n",
      "loss_val 1.9615417076991155\n",
      "acc val 0.47380957\n",
      "Epoch: 45/1000\n",
      "loss_tra 1.9371356114097265\n",
      "acc train 0.4935294\n",
      "loss_val 1.9593458496607268\n",
      "acc val 0.47469103\n",
      "Epoch: 51/1000\n",
      "loss_tra 1.9140580773353577\n",
      "acc train 0.50043917\n",
      "loss_val 1.9592750806074877\n",
      "acc val 0.47519746\n",
      "Epoch: 55/1000\n",
      "loss_tra 1.9179332199304\n",
      "acc train 0.4990706\n",
      "loss_val 1.958190340262193\n",
      "acc val 0.47569492\n",
      "Epoch: 56/1000\n",
      "loss_tra 1.9048363618228747\n",
      "acc train 0.5035613\n",
      "loss_val 1.9579034997866704\n",
      "acc val 0.47629765\n",
      "Epoch: 61/1000\n",
      "loss_tra 1.897878094341444\n",
      "acc train 0.505277\n",
      "loss_val 1.9563503632178674\n",
      "acc val 0.47733927\n",
      "Epoch: 65/1000\n",
      "loss_tra 1.900806346665258\n",
      "acc train 0.50414616\n",
      "loss_val 1.9552863515340364\n",
      "acc val 0.47713506\n",
      "Epoch: 70/1000\n",
      "loss_tra 1.894144924827244\n",
      "acc train 0.5060624\n",
      "loss_val 1.9548319165523236\n",
      "acc val 0.477933\n",
      "Epoch: 96/1000\n",
      "loss_tra 1.853311994801397\n",
      "acc train 0.518098\n",
      "loss_val 1.9544365543585558\n",
      "acc val 0.4782779\n",
      "Epoch: 102/1000\n",
      "loss_tra 1.8510164602943089\n",
      "acc train 0.5191029\n",
      "loss_val 1.9534616424487188\n",
      "acc val 0.47891614\n",
      "Epoch: 105/1000\n",
      "loss_tra 1.8531440382418425\n",
      "acc train 0.51801115\n",
      "loss_val 1.9520333867806654\n",
      "acc val 0.47971612\n",
      "Epoch: 107/1000\n",
      "loss_tra 1.8446396967639094\n",
      "acc train 0.5205306\n",
      "loss_val 1.9503134810007536\n",
      "acc val 0.47906715\n",
      "Epoch: 116/1000\n",
      "loss_tra 1.8323902140492978\n",
      "acc train 0.5243591\n",
      "loss_val 1.9496125945678124\n",
      "acc val 0.48083398\n",
      "Epoch: 121/1000\n",
      "loss_tra 1.8290186923483143\n",
      "acc train 0.52511364\n",
      "loss_val 1.9476034870514503\n",
      "acc val 0.48096383\n",
      "Epoch: 127/1000\n",
      "loss_tra 1.8266947601152503\n",
      "acc train 0.52583325\n",
      "loss_val 1.9474899768829346\n",
      "acc val 0.48116243\n",
      "Epoch: 141/1000\n",
      "loss_tra 1.8128397926040318\n",
      "acc train 0.5296005\n",
      "loss_val 1.9465926197858958\n",
      "acc val 0.48157603\n",
      "val_best 0.48157603\n",
      "    ###      use      fold: 3\n",
      "################ Feature info: ###############\n",
      "Node's feature shape:torch.Size([3655452, 300])\n",
      "# model parameters: 3421463\n",
      "Epoch: 0/1000\n",
      "loss_tra 2.589501765499944\n",
      "acc train 0.27483386\n",
      "loss_val 2.2960529694190392\n",
      "acc val 0.36965978\n",
      "Epoch: 1/1000\n",
      "loss_tra 2.331680903227433\n",
      "acc train 0.36730713\n",
      "loss_val 2.19167474599985\n",
      "acc val 0.39844596\n",
      "Epoch: 2/1000\n",
      "loss_tra 2.2622532647588978\n",
      "acc train 0.38948655\n",
      "loss_val 2.136782352740948\n",
      "acc val 0.41868326\n",
      "Epoch: 3/1000\n",
      "loss_tra 2.211506597892098\n",
      "acc train 0.40827826\n",
      "loss_val 2.09181913962731\n",
      "acc val 0.43246713\n",
      "Epoch: 4/1000\n",
      "loss_tra 2.1817232681357344\n",
      "acc train 0.41873163\n",
      "loss_val 2.0656743416419396\n",
      "acc val 0.44014886\n",
      "Epoch: 5/1000\n",
      "loss_tra 2.1292041177334995\n",
      "acc train 0.4357992\n",
      "loss_val 2.033025484818679\n",
      "acc val 0.45034927\n",
      "Epoch: 6/1000\n",
      "loss_tra 2.1126014605812404\n",
      "acc train 0.44098783\n",
      "loss_val 2.023703538454496\n",
      "acc val 0.45211622\n",
      "Epoch: 10/1000\n",
      "loss_tra 2.0709086096805076\n",
      "acc train 0.45333198\n",
      "loss_val 2.0012998351683984\n",
      "acc val 0.45949742\n",
      "Epoch: 11/1000\n",
      "loss_tra 2.0561616690262503\n",
      "acc train 0.45773664\n",
      "loss_val 1.9970047565606923\n",
      "acc val 0.4617879\n",
      "Epoch: 12/1000\n",
      "loss_tra 2.0567069639330327\n",
      "acc train 0.4577171\n",
      "loss_val 1.9968975644845228\n",
      "acc val 0.46241257\n",
      "Epoch: 15/1000\n",
      "loss_tra 2.0368390964425127\n",
      "acc train 0.4629644\n",
      "loss_val 1.9896442110721881\n",
      "acc val 0.4648488\n",
      "Epoch: 16/1000\n",
      "loss_tra 2.022333708016769\n",
      "acc train 0.467954\n",
      "loss_val 1.9853792969997113\n",
      "acc val 0.4656479\n",
      "Epoch: 17/1000\n",
      "loss_tra 2.0235371625941734\n",
      "acc train 0.4676168\n",
      "loss_val 1.9852349253801198\n",
      "acc val 0.4657143\n",
      "Epoch: 20/1000\n",
      "loss_tra 2.0108197310696476\n",
      "acc train 0.47139946\n",
      "loss_val 1.9794609821759737\n",
      "acc val 0.4684373\n",
      "Epoch: 21/1000\n",
      "loss_tra 1.9969677422357641\n",
      "acc train 0.47552675\n",
      "loss_val 1.9723793405752916\n",
      "acc val 0.46999738\n",
      "Epoch: 25/1000\n",
      "loss_tra 1.990144165184187\n",
      "acc train 0.47791895\n",
      "loss_val 1.9717208972344031\n",
      "acc val 0.47045666\n",
      "Epoch: 30/1000\n",
      "loss_tra 1.9716495980387148\n",
      "acc train 0.48372164\n",
      "loss_val 1.9690109399648814\n",
      "acc val 0.47232336\n",
      "Epoch: 31/1000\n",
      "loss_tra 1.9599766648334005\n",
      "acc train 0.48675007\n",
      "loss_val 1.9664244147447438\n",
      "acc val 0.47239125\n",
      "Epoch: 35/1000\n",
      "loss_tra 1.9588439065477123\n",
      "acc train 0.48732114\n",
      "loss_val 1.9643491965073805\n",
      "acc val 0.47338673\n",
      "Epoch: 37/1000\n",
      "loss_tra 1.9473367836164392\n",
      "acc train 0.49065363\n",
      "loss_val 1.9622782377096324\n",
      "acc val 0.47286928\n",
      "Epoch: 40/1000\n",
      "loss_tra 1.9461241323014964\n",
      "acc train 0.49108246\n",
      "loss_val 1.9617866002596343\n",
      "acc val 0.4749177\n",
      "Epoch: 42/1000\n",
      "loss_tra 1.9358362135679825\n",
      "acc train 0.49409685\n",
      "loss_val 1.9600117481671846\n",
      "acc val 0.47526264\n",
      "Epoch: 45/1000\n",
      "loss_tra 1.935591276832249\n",
      "acc train 0.49404994\n",
      "loss_val 1.9580366565630987\n",
      "acc val 0.4763853\n",
      "Epoch: 46/1000\n",
      "loss_tra 1.9227348716362662\n",
      "acc train 0.49812725\n",
      "loss_val 1.9527353506821852\n",
      "acc val 0.47601506\n",
      "val_best 0.47601506\n",
      "    ###      use      fold: 4\n",
      "################ Feature info: ###############\n",
      "Node's feature shape:torch.Size([3655452, 300])\n",
      "# model parameters: 3421463\n",
      "Epoch: 0/1000\n",
      "loss_tra 2.5952127643253493\n",
      "acc train 0.272081\n",
      "loss_val 2.329746567285978\n",
      "acc val 0.3582043\n",
      "Epoch: 1/1000\n",
      "loss_tra 2.341218318109927\n",
      "acc train 0.36425075\n",
      "loss_val 2.202288737663856\n",
      "acc val 0.39332688\n",
      "Epoch: 2/1000\n",
      "loss_tra 2.270306770697884\n",
      "acc train 0.38655594\n",
      "loss_val 2.1388329084102926\n",
      "acc val 0.41597122\n",
      "Epoch: 3/1000\n",
      "loss_tra 2.2165661894756816\n",
      "acc train 0.406975\n",
      "loss_val 2.0909780263900757\n",
      "acc val 0.43019623\n",
      "Epoch: 4/1000\n",
      "loss_tra 2.18408334462539\n",
      "acc train 0.41813573\n",
      "loss_val 2.0670912174078135\n",
      "acc val 0.43987992\n",
      "Epoch: 5/1000\n",
      "loss_tra 2.1329193415849104\n",
      "acc train 0.43464163\n",
      "loss_val 2.0337446561226478\n",
      "acc val 0.4492113\n",
      "Epoch: 6/1000\n",
      "loss_tra 2.1142492097357044\n",
      "acc train 0.4407103\n",
      "loss_val 2.025862299478971\n",
      "acc val 0.45216087\n",
      "Epoch: 7/1000\n",
      "loss_tra 2.112041437107584\n",
      "acc train 0.4408746\n",
      "loss_val 2.025214910507202\n",
      "acc val 0.45060104\n",
      "Epoch: 8/1000\n",
      "loss_tra 2.1136188486348026\n",
      "acc train 0.44022018\n",
      "loss_val 2.0247946106470547\n",
      "acc val 0.45139134\n",
      "Epoch: 9/1000\n",
      "loss_tra 2.1128404244132666\n",
      "acc train 0.44055766\n",
      "loss_val 2.0210321774849525\n",
      "acc val 0.45210475\n",
      "Epoch: 10/1000\n",
      "loss_tra 2.072836274167766\n",
      "acc train 0.45271623\n",
      "loss_val 1.9981529437578642\n",
      "acc val 0.45985112\n",
      "Epoch: 11/1000\n",
      "loss_tra 2.0590020107186358\n",
      "acc train 0.4572155\n",
      "loss_val 1.9952152188007648\n",
      "acc val 0.46168596\n",
      "Epoch: 15/1000\n",
      "loss_tra 2.0384467264880306\n",
      "acc train 0.46318126\n",
      "loss_val 1.986199562366192\n",
      "acc val 0.46445364\n",
      "Epoch: 16/1000\n",
      "loss_tra 2.0239747140718545\n",
      "acc train 0.46763763\n",
      "loss_val 1.9798304759539092\n",
      "acc val 0.4661925\n",
      "Epoch: 20/1000\n",
      "loss_tra 2.0143673445867454\n",
      "acc train 0.47049016\n",
      "loss_val 1.9745624844844525\n",
      "acc val 0.46783414\n",
      "Epoch: 25/1000\n",
      "loss_tra 1.9936341166496276\n",
      "acc train 0.47694468\n",
      "loss_val 1.9661147135954637\n",
      "acc val 0.4714325\n",
      "Epoch: 26/1000\n",
      "loss_tra 1.9805282986682393\n",
      "acc train 0.48087397\n",
      "loss_val 1.9653012385735145\n",
      "acc val 0.47164074\n",
      "Epoch: 30/1000\n",
      "loss_tra 1.9763408241064653\n",
      "acc train 0.48240337\n",
      "loss_val 1.965138513308305\n",
      "acc val 0.47259638\n",
      "Epoch: 31/1000\n",
      "loss_tra 1.9632519582043524\n",
      "acc train 0.48610982\n",
      "loss_val 1.9623801112174988\n",
      "acc val 0.47261527\n",
      "Epoch: 35/1000\n",
      "loss_tra 1.9617942410966625\n",
      "acc train 0.48647374\n",
      "loss_val 1.9623325650508587\n",
      "acc val 0.47389287\n",
      "Epoch: 36/1000\n",
      "loss_tra 1.948414165040721\n",
      "acc train 0.49043685\n",
      "loss_val 1.9593599026019757\n",
      "acc val 0.47483352\n",
      "Epoch: 40/1000\n",
      "loss_tra 1.948145978347115\n",
      "acc train 0.49051738\n",
      "loss_val 1.9589716792106628\n",
      "acc val 0.47462475\n",
      "Epoch: 41/1000\n",
      "loss_tra 1.93505591361419\n",
      "acc train 0.49423358\n",
      "loss_val 1.9588470871631916\n",
      "acc val 0.4745777\n",
      "Epoch: 45/1000\n",
      "loss_tra 1.9369468206944673\n",
      "acc train 0.49378434\n",
      "loss_val 1.9571154071734502\n",
      "acc val 0.4750851\n",
      "Epoch: 46/1000\n",
      "loss_tra 1.9251726534055627\n",
      "acc train 0.49721414\n",
      "loss_val 1.9527526176892793\n",
      "acc val 0.4767499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 50/1000\n",
      "loss_tra 1.9267287549765213\n",
      "acc train 0.49680573\n",
      "loss_val 1.9519365200629601\n",
      "acc val 0.47729352\n",
      "Epoch: 61/1000\n",
      "loss_tra 1.8992202318232991\n",
      "acc train 0.5052583\n",
      "loss_val 1.951660523047814\n",
      "acc val 0.47784764\n",
      "Epoch: 76/1000\n",
      "loss_tra 1.8776383363682292\n",
      "acc train 0.51147896\n",
      "loss_val 1.9512204069357653\n",
      "acc val 0.4782789\n",
      "Epoch: 81/1000\n",
      "loss_tra 1.8703834787659024\n",
      "acc train 0.5134174\n",
      "loss_val 1.951187761930319\n",
      "acc val 0.47858843\n",
      "Epoch: 83/1000\n",
      "loss_tra 1.881861708993497\n",
      "acc train 0.510037\n",
      "loss_val 1.9504552162610567\n",
      "acc val 0.47864723\n",
      "Epoch: 91/1000\n",
      "loss_tra 1.8583763625310814\n",
      "acc train 0.5170648\n",
      "loss_val 1.94994279054495\n",
      "acc val 0.4800654\n",
      "Epoch: 100/1000\n",
      "loss_tra 1.8574918669203053\n",
      "acc train 0.5171831\n",
      "loss_val 1.9481355410355787\n",
      "acc val 0.479256\n",
      "Epoch: 121/1000\n",
      "loss_tra 1.8315741632295692\n",
      "acc train 0.52505213\n",
      "loss_val 1.9475786135746882\n",
      "acc val 0.480146\n",
      "val_best 0.480146\n",
      "    ###      use      fold: 5\n",
      "################ Feature info: ###############\n",
      "Node's feature shape:torch.Size([3655452, 300])\n",
      "# model parameters: 3421463\n",
      "Epoch: 0/1000\n",
      "loss_tra 2.5957022034603616\n",
      "acc train 0.2715733\n",
      "loss_val 2.326613921385545\n",
      "acc val 0.36894777\n",
      "Epoch: 1/1000\n",
      "loss_tra 2.3363933407742046\n",
      "acc train 0.36631402\n",
      "loss_val 2.196176657309899\n",
      "acc val 0.39882082\n",
      "Epoch: 2/1000\n",
      "loss_tra 2.2616464998411097\n",
      "acc train 0.3899228\n",
      "loss_val 2.1339013759906473\n",
      "acc val 0.41811088\n",
      "Epoch: 3/1000\n",
      "loss_tra 2.2123850335245545\n",
      "acc train 0.4085266\n",
      "loss_val 2.091253784986643\n",
      "acc val 0.4302153\n",
      "Epoch: 4/1000\n",
      "loss_tra 2.1812938565793245\n",
      "acc train 0.41881058\n",
      "loss_val 2.078194728264442\n",
      "acc val 0.43537885\n",
      "Epoch: 5/1000\n",
      "loss_tra 2.13114114118659\n",
      "acc train 0.43477517\n",
      "loss_val 2.037059472157405\n",
      "acc val 0.448366\n",
      "Epoch: 6/1000\n",
      "loss_tra 2.1142213064691293\n",
      "acc train 0.44027218\n",
      "loss_val 2.0292909878950853\n",
      "acc val 0.45160675\n",
      "Epoch: 10/1000\n",
      "loss_tra 2.0711023988931077\n",
      "acc train 0.45313698\n",
      "loss_val 2.001978713732499\n",
      "acc val 0.45953444\n",
      "Epoch: 11/1000\n",
      "loss_tra 2.0552907301032026\n",
      "acc train 0.4582531\n",
      "loss_val 1.9970927421863263\n",
      "acc val 0.4610945\n",
      "Epoch: 15/1000\n",
      "loss_tra 2.034539296834365\n",
      "acc train 0.46418372\n",
      "loss_val 1.989462632399339\n",
      "acc val 0.46327078\n",
      "Epoch: 16/1000\n",
      "loss_tra 2.021195837725764\n",
      "acc train 0.46848112\n",
      "loss_val 1.9876413437036367\n",
      "acc val 0.4649716\n",
      "Epoch: 20/1000\n",
      "loss_tra 2.0105746756429257\n",
      "acc train 0.4712955\n",
      "loss_val 1.9827216405134935\n",
      "acc val 0.46665013\n",
      "Epoch: 21/1000\n",
      "loss_tra 1.9965665547744087\n",
      "acc train 0.4753613\n",
      "loss_val 1.9765411523672252\n",
      "acc val 0.4681938\n",
      "Epoch: 22/1000\n",
      "loss_tra 1.996912908554077\n",
      "acc train 0.47529155\n",
      "loss_val 1.9748975680424616\n",
      "acc val 0.4673595\n",
      "Epoch: 26/1000\n",
      "loss_tra 1.976588625493257\n",
      "acc train 0.4816743\n",
      "loss_val 1.974030036192674\n",
      "acc val 0.4698439\n",
      "Epoch: 30/1000\n",
      "loss_tra 1.9718000816262287\n",
      "acc train 0.48261252\n",
      "loss_val 1.971450883608598\n",
      "acc val 0.47149822\n",
      "Epoch: 31/1000\n",
      "loss_tra 1.9602915033050206\n",
      "acc train 0.4865905\n",
      "loss_val 1.9665728853299067\n",
      "acc val 0.47198704\n",
      "Epoch: 35/1000\n",
      "loss_tra 1.9565183318179586\n",
      "acc train 0.4875268\n",
      "loss_val 1.962956245128925\n",
      "acc val 0.47357416\n",
      "Epoch: 36/1000\n",
      "loss_tra 1.9438449481259221\n",
      "acc train 0.4915555\n",
      "loss_val 1.96001751606281\n",
      "acc val 0.47421402\n",
      "Epoch: 40/1000\n",
      "loss_tra 1.9433742035990176\n",
      "acc train 0.49113145\n",
      "loss_val 1.958978519989894\n",
      "acc val 0.4754794\n",
      "Epoch: 41/1000\n",
      "loss_tra 1.9299895286560058\n",
      "acc train 0.4954933\n",
      "loss_val 1.956087121596703\n",
      "acc val 0.47646612\n",
      "Epoch: 55/1000\n",
      "loss_tra 1.9118218219798544\n",
      "acc train 0.5003352\n",
      "loss_val 1.95496378495143\n",
      "acc val 0.47767776\n",
      "Epoch: 56/1000\n",
      "loss_tra 1.9011921296948973\n",
      "acc train 0.50379395\n",
      "loss_val 1.953210106262794\n",
      "acc val 0.47707784\n",
      "Epoch: 86/1000\n",
      "loss_tra 1.8573500705801922\n",
      "acc train 0.51692855\n",
      "loss_val 1.9502132030633779\n",
      "acc val 0.47931215\n",
      "Epoch: 111/1000\n",
      "loss_tra 1.8313607925954072\n",
      "acc train 0.5244677\n",
      "loss_val 1.9497207128084624\n",
      "acc val 0.48085245\n",
      "Epoch: 130/1000\n",
      "loss_tra 1.8275838820830634\n",
      "acc train 0.52530384\n",
      "loss_val 1.9488012057084303\n",
      "acc val 0.4810413\n",
      "val_best 0.4810413\n",
      "    ###      use      fold: 6\n",
      "################ Feature info: ###############\n",
      "Node's feature shape:torch.Size([3655452, 300])\n",
      "# model parameters: 3421463\n",
      "Epoch: 0/1000\n",
      "loss_tra 2.594734790014184\n",
      "acc train 0.27182356\n",
      "loss_val 2.34380474457374\n",
      "acc val 0.3551607\n",
      "Epoch: 1/1000\n",
      "loss_tra 2.345504629093668\n",
      "acc train 0.36295512\n",
      "loss_val 2.2034137065594015\n",
      "acc val 0.39673522\n",
      "Epoch: 2/1000\n",
      "loss_tra 2.269986907295559\n",
      "acc train 0.38660666\n",
      "loss_val 2.1472750351979184\n",
      "acc val 0.4165116\n",
      "Epoch: 3/1000\n",
      "loss_tra 2.2186804823253468\n",
      "acc train 0.40579927\n",
      "loss_val 2.0955252097203183\n",
      "acc val 0.43031093\n",
      "Epoch: 4/1000\n",
      "loss_tra 2.1855083403380022\n",
      "acc train 0.41782466\n",
      "loss_val 2.084870851956881\n",
      "acc val 0.43466693\n",
      "Epoch: 5/1000\n",
      "loss_tra 2.1328165665916776\n",
      "acc train 0.4343417\n",
      "loss_val 2.0434127083191505\n",
      "acc val 0.44692224\n",
      "Epoch: 6/1000\n",
      "loss_tra 2.1155551557955534\n",
      "acc train 0.43979537\n",
      "loss_val 2.033889990586501\n",
      "acc val 0.45005858\n",
      "Epoch: 8/1000\n",
      "loss_tra 2.111203451778578\n",
      "acc train 0.44116887\n",
      "loss_val 2.033419315631573\n",
      "acc val 0.4495419\n",
      "Epoch: 10/1000\n",
      "loss_tra 2.071649630173393\n",
      "acc train 0.45301515\n",
      "loss_val 2.0074663712428165\n",
      "acc val 0.4584699\n",
      "Epoch: 11/1000\n",
      "loss_tra 2.0562374757683797\n",
      "acc train 0.457682\n",
      "loss_val 2.0027918173716617\n",
      "acc val 0.4598228\n",
      "Epoch: 15/1000\n",
      "loss_tra 2.03670900489973\n",
      "acc train 0.46334556\n",
      "loss_val 1.991524379986983\n",
      "acc val 0.4647923\n",
      "Epoch: 16/1000\n",
      "loss_tra 2.022486534325973\n",
      "acc train 0.4680023\n",
      "loss_val 1.988761672606835\n",
      "acc val 0.46528068\n",
      "Epoch: 20/1000\n",
      "loss_tra 2.0120247478070468\n",
      "acc train 0.4707185\n",
      "loss_val 1.98215867464359\n",
      "acc val 0.46723393\n",
      "Epoch: 21/1000\n",
      "loss_tra 1.9984452957692354\n",
      "acc train 0.47515896\n",
      "loss_val 1.97688896380938\n",
      "acc val 0.46953535\n",
      "Epoch: 26/1000\n",
      "loss_tra 1.9772862418838169\n",
      "acc train 0.4816097\n",
      "loss_val 1.9756396137751067\n",
      "acc val 0.4693107\n",
      "Epoch: 30/1000\n",
      "loss_tra 1.9728447639423867\n",
      "acc train 0.4829698\n",
      "loss_val 1.9744327801924486\n",
      "acc val 0.47034267\n",
      "Epoch: 31/1000\n",
      "loss_tra 1.9607212559036586\n",
      "acc train 0.48683435\n",
      "loss_val 1.9710489740738502\n",
      "acc val 0.4709417\n",
      "Epoch: 35/1000\n",
      "loss_tra 1.9583611244740693\n",
      "acc train 0.4875074\n",
      "loss_val 1.9699781995553236\n",
      "acc val 0.47175133\n",
      "Epoch: 40/1000\n",
      "loss_tra 1.9442959184231965\n",
      "acc train 0.49204284\n",
      "loss_val 1.9691882454431975\n",
      "acc val 0.47337553\n",
      "Epoch: 41/1000\n",
      "loss_tra 1.9341287338215372\n",
      "acc train 0.49502414\n",
      "loss_val 1.9655119180679321\n",
      "acc val 0.47414765\n",
      "Epoch: 46/1000\n",
      "loss_tra 1.9234117482019508\n",
      "acc train 0.49784678\n",
      "loss_val 1.9638373118180494\n",
      "acc val 0.47415859\n",
      "Epoch: 50/1000\n",
      "loss_tra 1.9246686878411665\n",
      "acc train 0.49707493\n",
      "loss_val 1.9603873216188872\n",
      "acc val 0.4752475\n",
      "Epoch: 51/1000\n",
      "loss_tra 1.9132406426512676\n",
      "acc train 0.5006457\n",
      "loss_val 1.9590434340330272\n",
      "acc val 0.4764876\n",
      "Epoch: 71/1000\n",
      "loss_tra 1.8799307450004246\n",
      "acc train 0.5104257\n",
      "loss_val 1.958688850586231\n",
      "acc val 0.47758546\n",
      "Epoch: 85/1000\n",
      "loss_tra 1.8732527681018996\n",
      "acc train 0.5123879\n",
      "loss_val 1.9564943955494807\n",
      "acc val 0.47888023\n",
      "Epoch: 90/1000\n",
      "loss_tra 1.8682738366334335\n",
      "acc train 0.51383543\n",
      "loss_val 1.954678136568803\n",
      "acc val 0.4789849\n",
      "Epoch: 116/1000\n",
      "loss_tra 1.833137571811676\n",
      "acc train 0.52415246\n",
      "loss_val 1.9542875381616445\n",
      "acc val 0.47994947\n",
      "Epoch: 130/1000\n",
      "loss_tra 1.832540872304336\n",
      "acc train 0.52437186\n",
      "loss_val 1.9539788686312163\n",
      "acc val 0.480251\n",
      "Epoch: 138/1000\n",
      "loss_tra 1.8283463286316912\n",
      "acc train 0.5257912\n",
      "loss_val 1.953490715760451\n",
      "acc val 0.47985607\n",
      "Epoch: 141/1000\n",
      "loss_tra 1.8118527816689534\n",
      "acc train 0.5307192\n",
      "loss_val 1.9526693408305829\n",
      "acc val 0.4808321\n",
      "Epoch: 151/1000\n",
      "loss_tra 1.805381969783617\n",
      "acc train 0.53222144\n",
      "loss_val 1.9511026464975798\n",
      "acc val 0.482004\n",
      "Epoch: 152/1000\n",
      "loss_tra 1.8065954908080724\n",
      "acc train 0.532026\n",
      "loss_val 1.950337827205658\n",
      "acc val 0.48173475\n",
      "Epoch: 160/1000\n",
      "loss_tra 1.8082246982533\n",
      "acc train 0.53189254\n",
      "loss_val 1.9497437477111816\n",
      "acc val 0.48302162\n",
      "Epoch: 165/1000\n",
      "loss_tra 1.8044192464455315\n",
      "acc train 0.53243273\n",
      "loss_val 1.9455845310137823\n",
      "acc val 0.48220363\n",
      "val_best 0.48220363\n",
      "    ###      use      fold: 7\n",
      "################ Feature info: ###############\n",
      "Node's feature shape:torch.Size([3655452, 300])\n",
      "# model parameters: 3421463\n",
      "Epoch: 0/1000\n",
      "loss_tra 2.5936868916387144\n",
      "acc train 0.27345982\n",
      "loss_val 2.2937562190569363\n",
      "acc val 0.37126473\n",
      "Epoch: 1/1000\n",
      "loss_tra 2.334686991442805\n",
      "acc train 0.3657047\n",
      "loss_val 2.1989064858509946\n",
      "acc val 0.3971659\n",
      "Epoch: 2/1000\n",
      "loss_tra 2.267910985324694\n",
      "acc train 0.38770407\n",
      "loss_val 2.1311592964025645\n",
      "acc val 0.41875347\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3/1000\n",
      "loss_tra 2.2126709658166637\n",
      "acc train 0.40912223\n",
      "loss_val 2.0851462254157433\n",
      "acc val 0.4325423\n",
      "Epoch: 4/1000\n",
      "loss_tra 2.182872584591741\n",
      "acc train 0.41880324\n",
      "loss_val 2.0824546813964844\n",
      "acc val 0.4364199\n",
      "Epoch: 5/1000\n",
      "loss_tra 2.1318112280057826\n",
      "acc train 0.43465576\n",
      "loss_val 2.0387033315805287\n",
      "acc val 0.44683436\n",
      "Epoch: 6/1000\n",
      "loss_tra 2.115119070592134\n",
      "acc train 0.4398281\n",
      "loss_val 2.031212416978983\n",
      "acc val 0.44936034\n",
      "Epoch: 7/1000\n",
      "loss_tra 2.1125762721766597\n",
      "acc train 0.44066706\n",
      "loss_val 2.0287905748073873\n",
      "acc val 0.45017797\n",
      "Epoch: 8/1000\n",
      "loss_tra 2.112057887989542\n",
      "acc train 0.44054157\n",
      "loss_val 2.0245107183089623\n",
      "acc val 0.45172817\n",
      "Epoch: 10/1000\n",
      "loss_tra 2.0722732429919035\n",
      "acc train 0.45301926\n",
      "loss_val 1.998678968502925\n",
      "acc val 0.45887578\n",
      "Epoch: 11/1000\n",
      "loss_tra 2.0571269118267557\n",
      "acc train 0.45753366\n",
      "loss_val 1.9958227964547963\n",
      "acc val 0.45999205\n",
      "Epoch: 15/1000\n",
      "loss_tra 2.0379762151966925\n",
      "acc train 0.46293077\n",
      "loss_val 1.9816371569266686\n",
      "acc val 0.46527243\n",
      "Epoch: 16/1000\n",
      "loss_tra 2.0240354112956833\n",
      "acc train 0.46756274\n",
      "loss_val 1.9810007076997023\n",
      "acc val 0.46524483\n",
      "Epoch: 20/1000\n",
      "loss_tra 2.013098613075588\n",
      "acc train 0.47056866\n",
      "loss_val 1.9771660016133235\n",
      "acc val 0.46773848\n",
      "Epoch: 21/1000\n",
      "loss_tra 1.998745974768763\n",
      "acc train 0.4749541\n",
      "loss_val 1.9723256276204035\n",
      "acc val 0.4689989\n",
      "Epoch: 25/1000\n",
      "loss_tra 1.991251782230709\n",
      "acc train 0.47716048\n",
      "loss_val 1.9682049292784471\n",
      "acc val 0.47049174\n",
      "Epoch: 26/1000\n",
      "loss_tra 1.977681595346202\n",
      "acc train 0.48138586\n",
      "loss_val 1.9653312747295086\n",
      "acc val 0.4717895\n",
      "Epoch: 30/1000\n",
      "loss_tra 1.9748960422432942\n",
      "acc train 0.48220095\n",
      "loss_val 1.9611672575657184\n",
      "acc val 0.4716462\n",
      "Epoch: 31/1000\n",
      "loss_tra 1.962928645507149\n",
      "acc train 0.4859018\n",
      "loss_val 1.9596852018282964\n",
      "acc val 0.47291586\n",
      "Epoch: 32/1000\n",
      "loss_tra 1.9636639185573743\n",
      "acc train 0.48573607\n",
      "loss_val 1.9586647748947144\n",
      "acc val 0.4729157\n",
      "Epoch: 35/1000\n",
      "loss_tra 1.9593563795089721\n",
      "acc train 0.48704144\n",
      "loss_val 1.9585786507679865\n",
      "acc val 0.47474653\n",
      "Epoch: 36/1000\n",
      "loss_tra 1.9473659867825714\n",
      "acc train 0.4904961\n",
      "loss_val 1.9573256419255183\n",
      "acc val 0.47470963\n",
      "Epoch: 40/1000\n",
      "loss_tra 1.9457467535267705\n",
      "acc train 0.49108464\n",
      "loss_val 1.9553482945148761\n",
      "acc val 0.47502702\n",
      "Epoch: 41/1000\n",
      "loss_tra 1.9344341221063033\n",
      "acc train 0.4945361\n",
      "loss_val 1.9527941667116606\n",
      "acc val 0.47634205\n",
      "Epoch: 42/1000\n",
      "loss_tra 1.9365793456201967\n",
      "acc train 0.49398896\n",
      "loss_val 1.9515921015005846\n",
      "acc val 0.4767677\n",
      "Epoch: 46/1000\n",
      "loss_tra 1.9231526260790617\n",
      "acc train 0.4977161\n",
      "loss_val 1.9511978442852314\n",
      "acc val 0.4767843\n",
      "Epoch: 50/1000\n",
      "loss_tra 1.9239266359287759\n",
      "acc train 0.49767232\n",
      "loss_val 1.9503609767326942\n",
      "acc val 0.47730306\n",
      "Epoch: 51/1000\n",
      "loss_tra 1.9133882481118907\n",
      "acc train 0.5004285\n",
      "loss_val 1.9457734869076655\n",
      "acc val 0.47871125\n",
      "Epoch: 71/1000\n",
      "loss_tra 1.8779109498728876\n",
      "acc train 0.5110498\n",
      "loss_val 1.9444511349384601\n",
      "acc val 0.4798675\n",
      "Epoch: 75/1000\n",
      "loss_tra 1.883619304843571\n",
      "acc train 0.50932634\n",
      "loss_val 1.9414319120920622\n",
      "acc val 0.47945988\n",
      "val_best 0.47945988\n",
      "    ###      use      fold: 8\n",
      "################ Feature info: ###############\n",
      "Node's feature shape:torch.Size([3655452, 300])\n",
      "# model parameters: 3421463\n",
      "Epoch: 0/1000\n",
      "loss_tra 2.5850598646246867\n",
      "acc train 0.2771119\n",
      "loss_val 2.3394126892089844\n",
      "acc val 0.35915953\n",
      "Epoch: 1/1000\n",
      "loss_tra 2.3397956392039423\n",
      "acc train 0.3645612\n",
      "loss_val 2.201175515468304\n",
      "acc val 0.39432797\n",
      "Epoch: 2/1000\n",
      "loss_tra 2.265568699007449\n",
      "acc train 0.38815767\n",
      "loss_val 2.1402409810286303\n",
      "acc val 0.41413623\n",
      "Epoch: 3/1000\n",
      "loss_tra 2.2164253545844037\n",
      "acc train 0.40612516\n",
      "loss_val 2.101216829740084\n",
      "acc val 0.4301755\n",
      "Epoch: 4/1000\n",
      "loss_tra 2.184719206975854\n",
      "acc train 0.41800836\n",
      "loss_val 2.075202841025132\n",
      "acc val 0.43678766\n",
      "Epoch: 5/1000\n",
      "loss_tra 2.1338588403618854\n",
      "acc train 0.43446875\n",
      "loss_val 2.035761393033541\n",
      "acc val 0.4497742\n",
      "Epoch: 6/1000\n",
      "loss_tra 2.1166123493858007\n",
      "acc train 0.43957904\n",
      "loss_val 2.0241544980269213\n",
      "acc val 0.45263368\n",
      "Epoch: 10/1000\n",
      "loss_tra 2.0745413427767545\n",
      "acc train 0.45198178\n",
      "loss_val 2.000183802384597\n",
      "acc val 0.46129957\n",
      "Epoch: 11/1000\n",
      "loss_tra 2.0574004966279733\n",
      "acc train 0.45725214\n",
      "loss_val 1.9985909920472364\n",
      "acc val 0.4614404\n",
      "Epoch: 15/1000\n",
      "loss_tra 2.03759460138238\n",
      "acc train 0.4630245\n",
      "loss_val 1.981898504954118\n",
      "acc val 0.4659846\n",
      "Epoch: 16/1000\n",
      "loss_tra 2.025235970642256\n",
      "acc train 0.4671483\n",
      "loss_val 1.9787701276632457\n",
      "acc val 0.46777013\n",
      "Epoch: 20/1000\n",
      "loss_tra 2.012468099075815\n",
      "acc train 0.47120896\n",
      "loss_val 1.9749220059468195\n",
      "acc val 0.47038132\n",
      "Epoch: 21/1000\n",
      "loss_tra 1.9996115917744843\n",
      "acc train 0.47517812\n",
      "loss_val 1.96906323157824\n",
      "acc val 0.47164166\n",
      "Epoch: 26/1000\n",
      "loss_tra 1.9795727087103803\n",
      "acc train 0.4811694\n",
      "loss_val 1.9663015695718618\n",
      "acc val 0.47218066\n",
      "Epoch: 30/1000\n",
      "loss_tra 1.9747772963150687\n",
      "acc train 0.48263046\n",
      "loss_val 1.9648966972644513\n",
      "acc val 0.4733287\n",
      "Epoch: 31/1000\n",
      "loss_tra 1.9631370881329413\n",
      "acc train 0.48598835\n",
      "loss_val 1.9586443396715016\n",
      "acc val 0.47439086\n",
      "Epoch: 41/1000\n",
      "loss_tra 1.9354861632637355\n",
      "acc train 0.49462003\n",
      "loss_val 1.9564113387694726\n",
      "acc val 0.47632393\n",
      "Epoch: 46/1000\n",
      "loss_tra 1.9255125356757123\n",
      "acc train 0.49743393\n",
      "loss_val 1.9560196307989268\n",
      "acc val 0.4766806\n",
      "Epoch: 50/1000\n",
      "loss_tra 1.927086960232776\n",
      "acc train 0.49706188\n",
      "loss_val 1.9537500876646776\n",
      "acc val 0.477968\n",
      "Epoch: 51/1000\n",
      "loss_tra 1.9152980472730554\n",
      "acc train 0.50023484\n",
      "loss_val 1.9530703104459322\n",
      "acc val 0.47796816\n",
      "Epoch: 55/1000\n",
      "loss_tra 1.9176603011463\n",
      "acc train 0.49955633\n",
      "loss_val 1.9499414333930383\n",
      "acc val 0.47860685\n",
      "Epoch: 75/1000\n",
      "loss_tra 1.8884987592697144\n",
      "acc train 0.508068\n",
      "loss_val 1.9483242768507738\n",
      "acc val 0.4791028\n",
      "Epoch: 81/1000\n",
      "loss_tra 1.8714890464492466\n",
      "acc train 0.51319355\n",
      "loss_val 1.9482876291641822\n",
      "acc val 0.47980818\n",
      "val_best 0.47980818\n",
      "    ###      use      fold: 9\n",
      "################ Feature info: ###############\n",
      "Node's feature shape:torch.Size([3655452, 300])\n",
      "# model parameters: 3421463\n",
      "Epoch: 0/1000\n",
      "loss_tra 2.596196815241938\n",
      "acc train 0.27151853\n",
      "loss_val 2.3410665622124305\n",
      "acc val 0.35459608\n",
      "Epoch: 1/1000\n",
      "loss_tra 2.347014604444089\n",
      "acc train 0.36228895\n",
      "loss_val 2.22164393388308\n",
      "acc val 0.38985887\n",
      "Epoch: 2/1000\n",
      "loss_tra 2.273922889128975\n",
      "acc train 0.3843492\n",
      "loss_val 2.151495722623972\n",
      "acc val 0.41242716\n",
      "Epoch: 3/1000\n",
      "loss_tra 2.221380461817202\n",
      "acc train 0.40342546\n",
      "loss_val 2.096315998297471\n",
      "acc val 0.4286995\n",
      "Epoch: 4/1000\n",
      "loss_tra 2.1840647987697435\n",
      "acc train 0.41741326\n",
      "loss_val 2.0791536294496975\n",
      "acc val 0.43626133\n",
      "Epoch: 5/1000\n",
      "loss_tra 2.132669919470082\n",
      "acc train 0.43463987\n",
      "loss_val 2.0423548221588135\n",
      "acc val 0.44619602\n",
      "Epoch: 6/1000\n",
      "loss_tra 2.1165546168451725\n",
      "acc train 0.43955445\n",
      "loss_val 2.0320391471569357\n",
      "acc val 0.45027125\n",
      "Epoch: 10/1000\n",
      "loss_tra 2.072422202255415\n",
      "acc train 0.45331162\n",
      "loss_val 2.007075461057516\n",
      "acc val 0.45848042\n",
      "Epoch: 11/1000\n",
      "loss_tra 2.0590213677157525\n",
      "acc train 0.45708418\n",
      "loss_val 2.0014412907453685\n",
      "acc val 0.4596635\n",
      "Epoch: 15/1000\n",
      "loss_tra 2.0374454897382983\n",
      "acc train 0.46335584\n",
      "loss_val 1.992205262184143\n",
      "acc val 0.46244425\n",
      "Epoch: 16/1000\n",
      "loss_tra 2.023421373056329\n",
      "acc train 0.4676355\n",
      "loss_val 1.9902001940287077\n",
      "acc val 0.4628286\n",
      "Epoch: 17/1000\n",
      "loss_tra 2.022963182822518\n",
      "acc train 0.46785045\n",
      "loss_val 1.9901623175694392\n",
      "acc val 0.4631851\n",
      "Epoch: 20/1000\n",
      "loss_tra 2.0108274833015773\n",
      "acc train 0.47166\n",
      "loss_val 1.9832791777757497\n",
      "acc val 0.46628636\n",
      "Epoch: 21/1000\n",
      "loss_tra 1.9995324352513189\n",
      "acc train 0.47512233\n",
      "loss_val 1.9831500190954943\n",
      "acc val 0.46668884\n",
      "Epoch: 22/1000\n",
      "loss_tra 2.0001915812492372\n",
      "acc train 0.47517726\n",
      "loss_val 1.9800412104679987\n",
      "acc val 0.46750015\n",
      "Epoch: 25/1000\n",
      "loss_tra 1.990424368692481\n",
      "acc train 0.47789553\n",
      "loss_val 1.97626059788924\n",
      "acc val 0.4688575\n",
      "Epoch: 26/1000\n",
      "loss_tra 1.9784515785134358\n",
      "acc train 0.48148456\n",
      "loss_val 1.9744153252014747\n",
      "acc val 0.46935317\n",
      "Epoch: 30/1000\n",
      "loss_tra 1.973388759986214\n",
      "acc train 0.4830114\n",
      "loss_val 1.9729374509591322\n",
      "acc val 0.46978807\n",
      "Epoch: 31/1000\n",
      "loss_tra 1.9603295590566552\n",
      "acc train 0.4869605\n",
      "loss_val 1.9696093109937816\n",
      "acc val 0.47131813\n",
      "Epoch: 35/1000\n",
      "loss_tra 1.957554322740306\n",
      "acc train 0.4879121\n",
      "loss_val 1.9661884812208323\n",
      "acc val 0.47244662\n",
      "Epoch: 45/1000\n",
      "loss_tra 1.9355403252269912\n",
      "acc train 0.49395016\n",
      "loss_val 1.9647711194478548\n",
      "acc val 0.47415775\n",
      "Epoch: 46/1000\n",
      "loss_tra 1.9228255904239158\n",
      "acc train 0.49812025\n",
      "loss_val 1.964264269058521\n",
      "acc val 0.47402203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 50/1000\n",
      "loss_tra 1.923234394322271\n",
      "acc train 0.49783716\n",
      "loss_val 1.961644681600424\n",
      "acc val 0.47460625\n",
      "Epoch: 55/1000\n",
      "loss_tra 1.914259135723114\n",
      "acc train 0.50077486\n",
      "loss_val 1.9610547469212458\n",
      "acc val 0.47509304\n",
      "Epoch: 56/1000\n",
      "loss_tra 1.904486524540445\n",
      "acc train 0.5038348\n",
      "loss_val 1.9605921231783354\n",
      "acc val 0.47556347\n",
      "Epoch: 70/1000\n",
      "loss_tra 1.8935004819994388\n",
      "acc train 0.5068628\n",
      "loss_val 1.9592926043730516\n",
      "acc val 0.47651464\n",
      "Epoch: 100/1000\n",
      "loss_tra 1.8560731359150098\n",
      "acc train 0.51782584\n",
      "loss_val 1.9586470539753253\n",
      "acc val 0.4774434\n",
      "Epoch: 106/1000\n",
      "loss_tra 1.8406657410704572\n",
      "acc train 0.5224136\n",
      "loss_val 1.9570633539786706\n",
      "acc val 0.47850126\n",
      "Epoch: 128/1000\n",
      "loss_tra 1.8338965193085048\n",
      "acc train 0.5243157\n",
      "loss_val 1.9569996916330779\n",
      "acc val 0.4785511\n",
      "Epoch: 132/1000\n",
      "loss_tra 1.8218416405760725\n",
      "acc train 0.52748066\n",
      "loss_val 1.9565120752041156\n",
      "acc val 0.4788385\n",
      "Epoch: 136/1000\n",
      "loss_tra 1.8169071109398551\n",
      "acc train 0.5292233\n",
      "loss_val 1.9554472749049847\n",
      "acc val 0.4803539\n",
      "Epoch: 160/1000\n",
      "loss_tra 1.8103693417880846\n",
      "acc train 0.53154093\n",
      "loss_val 1.9547071319359999\n",
      "acc val 0.48077577\n",
      "Epoch: 165/1000\n",
      "loss_tra 1.8062039473782414\n",
      "acc train 0.5322782\n",
      "loss_val 1.9506460153139555\n",
      "acc val 0.48157656\n",
      "Epoch: 185/1000\n",
      "loss_tra 1.7962697562964067\n",
      "acc train 0.5351691\n",
      "loss_val 1.9501623098666852\n",
      "acc val 0.48111153\n",
      "val_best 0.48111153\n"
     ]
    }
   ],
   "source": [
    "base_path = 'DGL'\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group[\"lr\"] = 0.001 + (epoch % 5)*0.001\n",
    "\n",
    "n_epochs = 1000\n",
    "device = 'cuda:0'\n",
    "\n",
    "for fold in range(10):\n",
    "    labels, tr_label_idx, val_label_idx, test_label_idx, node_feat = load_dgl_graph_k_fold(base_path,fold)\n",
    "    batch_size = 4096\n",
    "    train_data_loader = FastTensorDataLoader(\n",
    "        node_feat[tr_label_idx],\n",
    "        labels[tr_label_idx],\n",
    "        batch_size=batch_size, shuffle=True)\n",
    "    valid_data_loader = FastTensorDataLoader(\n",
    "        node_feat[val_label_idx],\n",
    "        labels[val_label_idx],\n",
    "        batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    model = ISO_Node_NN().to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0003, weight_decay=0)\n",
    "    print('# model parameters:', sum(param.numel() for param in model.parameters()))\n",
    "    \n",
    "    loss_tra = []\n",
    "    loss_val = []\n",
    "    val_best = 1e9\n",
    "    stop_count = 0\n",
    "    for epoch in range(n_epochs):\n",
    "        adjust_learning_rate(optimizer, epoch)\n",
    "        model.train()\n",
    "        epoch_loss = []\n",
    "        \n",
    "        tra_acc_list = []\n",
    "        for X_sequence, target in train_data_loader:\n",
    "            X_sequence, target = X_sequence.to(device), target.to(device)\n",
    "\n",
    "            y_hat = model(X_sequence)\n",
    "            train_loss = custom_loss_function(y_hat, target)\n",
    "\n",
    "            val_batch_pred = torch.sum(torch.argmax(y_hat, dim=1) == target) / torch.tensor(target.shape[0])\n",
    "            tra_acc_list.append(val_batch_pred.detach().cpu().numpy())\n",
    "\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            epoch_loss.append(train_loss.item())\n",
    "        loss_tra = np.mean(epoch_loss)\n",
    "\n",
    "        # 验证集\n",
    "        model.eval()\n",
    "        epoch_loss = []\n",
    "        val_acc_list = []\n",
    "        for X_sequence, target in valid_data_loader:\n",
    "            X_sequence, target = X_sequence.to(device), target.to(device)\n",
    "            y_hat = model(X_sequence)\n",
    "            valid_loss = custom_loss_function(y_hat, target)\n",
    "            epoch_loss.append(valid_loss.item())\n",
    "\n",
    "            val_batch_pred = torch.sum(torch.argmax(y_hat, dim=1) == target) / torch.tensor(target.shape[0])\n",
    "            val_acc_list.append(val_batch_pred.detach().cpu().numpy())\n",
    "\n",
    "\n",
    "        loss_val = np.mean(epoch_loss)\n",
    "        if loss_val < val_best:\n",
    "            val_best = loss_val\n",
    "            acc_best = np.mean(val_acc_list)\n",
    "            stop_count = 0\n",
    "            best_model = deepcopy(model)\n",
    "            print(\"Epoch: {}/{}\".format(epoch, n_epochs))\n",
    "            print('loss_tra',loss_tra)\n",
    "            print('acc train',np.mean(tra_acc_list))\n",
    "            print('loss_val',loss_val)\n",
    "            print('acc val',np.mean(val_acc_list))\n",
    "        else:\n",
    "            stop_count += 1\n",
    "        if stop_count == 30:\n",
    "            break\n",
    "    \n",
    "    print('val_best',acc_best)\n",
    "    torch.save(best_model.state_dict(), f'dnn_fold_{fold}_balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_best 0.48111153\n"
     ]
    }
   ],
   "source": [
    "print('val_best',acc_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best  0.48996183\n",
    "class ISO_Node_NN(nn.Module):  \n",
    "\n",
    "    def __init__(self): \n",
    "        super(ISO_Node_NN, self).__init__()        \n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(300,2048),\n",
    "            nn.BatchNorm1d(2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(2048,1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(1024,512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(512,256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256,128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128,64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(64, 23),\n",
    "        )\n",
    "        \n",
    "\n",
    "    def forward(self, x):  \n",
    "        x = self.net(x)\n",
    "        return x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
