{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################ Graph info: ###############\n",
      "16.915180393560085\n",
      "16.915180393560085\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import dgl\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0, 1\"\n",
    "import torch\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "from tqdm import tqdm\n",
    "\n",
    "BASE_PATH = 'Z:/DataScience/DGL'\n",
    "import pickle\n",
    "with open(os.path.join(BASE_PATH, 'labels.pkl'), 'rb') as f:\n",
    "    label_data = pickle.load(f)\n",
    "\n",
    "labels = torch.from_numpy(label_data['label'])\n",
    "\n",
    "graphs, _ = dgl.load_graphs(os.path.join(BASE_PATH, 'graph.bin'))\n",
    "graph = graphs[0]\n",
    "degrees = graph.out_degrees() + graph.in_degrees()\n",
    "graph = dgl.to_bidirected(graph, copy_ndata=True)\n",
    "graph = dgl.add_self_loop(graph)\n",
    "print('################ Graph info: ###############')\n",
    "\n",
    "print(np.mean(graph.in_degrees().numpy()))\n",
    "print(np.mean(graph.out_degrees().numpy()))\n",
    "\n",
    "EMB_SIZE = 32\n",
    "\n",
    "nodes = []\n",
    "for repeat in range(10):\n",
    "    nodes.extend([i for i in range(graph.num_nodes())])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_feat = np.load(BASE_PATH + '/features.npy')\n",
    "node_info = np.load(BASE_PATH + '/node_info.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3655452\n",
      "Wall time: 10min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sample_times = 50\n",
    "nodes = []\n",
    "num_nodes  = int(graph.num_nodes())\n",
    "useful_index = torch.where(labels[:num_nodes] != -1)[0].numpy()\n",
    "train_index, valid_index = train_test_split(useful_index, test_size=0.2)\n",
    "print(num_nodes)\n",
    "walk_label_features = []\n",
    "preds = []\n",
    "for i in range(num_nodes):\n",
    "    for j in range(sample_times):\n",
    "        nodes.append(i)\n",
    "s = dgl.sampling.node2vec_random_walk(graph, nodes, 0.1, 1, walk_length=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 3655452/3655452 [10:10<00:00, 5992.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5857910480951597\n"
     ]
    }
   ],
   "source": [
    "for k in tqdm(range(num_nodes)):\n",
    "    select_index = s[k *sample_times : (k+1)*sample_times, 1:] != s[sample_times*k][0]\n",
    "    select_nei = s[k *sample_times : (k+1)*sample_times, 1:][select_index]\n",
    "    hop5_nei_labels = labels[select_nei]\n",
    "    hop5_labels = torch.zeros(hop5_nei_labels.shape[0], 24)\n",
    "    if len(hop5_nei_labels) == 0:\n",
    "        walk_label_features.append(torch.zeros(1, 24))\n",
    "    else:\n",
    "        hop5_labels[np.arange(hop5_labels.shape[0]).reshape(-1, 1), hop5_nei_labels.numpy().reshape(-1, 1)] = 1\n",
    "        mean_hop5_labels = hop5_labels.mean(0)\n",
    "        walk_label_features.append(mean_hop5_labels.unsqueeze(0))\n",
    "        if labels[s[sample_times*k][0]] == -1:\n",
    "            continue\n",
    "        preds.append(labels[s[sample_times*k][0]] in mean_hop5_labels[:-1].topk(1).indices)\n",
    "walk_label_features = torch.cat(walk_label_features)\n",
    "# np.save(BASE_PATH + f'/walklength{10}_sampletimes{sample_times}.npy', walk_label_features)\n",
    "print(np.mean(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "walk_label_features = walk_label_features.cpu().numpy()\n",
    "np.save('walk_label_features.npy',walk_label_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.00408163 0.01632653 ... 0.0122449  0.         0.6530612 ]\n",
      " [0.0020284  0.09330629 0.0020284  ... 0.0040568  0.         0.78498983]\n",
      " ...\n",
      " [0.         0.         0.01830664 ... 0.         0.         0.49427918]\n",
      " [0.         0.         0.         ... 0.         0.24130435 0.6956522 ]\n",
      " [0.         0.         0.         ... 0.         0.         0.95110023]]\n"
     ]
    }
   ],
   "source": [
    "walk_label_features = np.load('walk_label_features.npy')\n",
    "print(walk_label_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda3/envs/torch1.8.1/lib/python3.6/site-packages/ipykernel_launcher.py:1: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/data/anaconda3/envs/torch1.8.1/lib/python3.6/site-packages/ipykernel_launcher.py:2: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "innode_feat_mean = node_info[:,:25]/node_info[:,:25].sum(axis=-1).reshape(-1, 1)\n",
    "outnode_feat_mean = node_info[:,25:]/node_info[:,25:].sum(axis=-1).reshape(-1, 1)\n",
    "node_feat_mean = innode_feat_mean + outnode_feat_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = walk_label_features[train_index].numpy()\n",
    "train_ori_features = node_feat[train_index]\n",
    "train_node_info = node_info[train_index]\n",
    "# train_innode_feat_mean = innode_feat_mean[train_index]\n",
    "# train_outnode_feat_mean = outnode_feat_mean[train_index]\n",
    "# train_node_feat_mean = node_feat_mean[train_index]\n",
    "train_x = np.concatenate([train_x, train_ori_features, train_node_info], axis=-1)\n",
    "\n",
    "train_y = labels[train_index].numpy()\n",
    "\n",
    "valid_x = walk_label_features[valid_index].numpy()\n",
    "valid_ori_features = node_feat[valid_index]\n",
    "valid_node_info = node_info[valid_index]\n",
    "\n",
    "# valid_innode_feat_mean = innode_feat_mean[valid_index]\n",
    "# valid_outnode_feat_mean = outnode_feat_mean[valid_index]\n",
    "# valid_node_feat_mean = node_feat_mean[valid_index]\n",
    "\n",
    "valid_x = np.concatenate([valid_x, valid_ori_features, valid_node_info], axis=-1)\n",
    "\n",
    "valid_y = labels[valid_index].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbt = CatBoostClassifier(iterations=4000,learning_rate=0.2,task_type='GPU', loss_function='MultiClass', eval_metric='Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.3594257\ttest: 0.3602478\tbest: 0.3602478 (0)\ttotal: 284ms\tremaining: 18m 54s\n",
      "100:\tlearn: 0.5696519\ttest: 0.5675495\tbest: 0.5675495 (100)\ttotal: 14.5s\tremaining: 9m 18s\n",
      "200:\tlearn: 0.5910455\ttest: 0.5856073\tbest: 0.5856073 (200)\ttotal: 30.5s\tremaining: 9m 37s\n",
      "300:\tlearn: 0.6014293\ttest: 0.5927261\tbest: 0.5927261 (300)\ttotal: 46.9s\tremaining: 9m 36s\n",
      "400:\tlearn: 0.6088616\ttest: 0.5963741\tbest: 0.5964124 (395)\ttotal: 1m 3s\tremaining: 9m 28s\n",
      "500:\tlearn: 0.6146819\ttest: 0.5981980\tbest: 0.5983177 (495)\ttotal: 1m 19s\tremaining: 9m 15s\n",
      "600:\tlearn: 0.6191736\ttest: 0.5995912\tbest: 0.5996199 (599)\ttotal: 1m 35s\tremaining: 9m\n",
      "700:\tlearn: 0.6236606\ttest: 0.6011040\tbest: 0.6011901 (696)\ttotal: 1m 51s\tremaining: 8m 44s\n",
      "800:\tlearn: 0.6279967\ttest: 0.6020854\tbest: 0.6021045 (796)\ttotal: 2m 7s\tremaining: 8m 28s\n",
      "900:\tlearn: 0.6321163\ttest: 0.6030716\tbest: 0.6031529 (891)\ttotal: 2m 23s\tremaining: 8m 12s\n",
      "1000:\tlearn: 0.6359486\ttest: 0.6031960\tbest: 0.6033971 (973)\ttotal: 2m 39s\tremaining: 7m 57s\n",
      "1100:\tlearn: 0.6397210\ttest: 0.6037179\tbest: 0.6037418 (1099)\ttotal: 2m 55s\tremaining: 7m 41s\n",
      "1200:\tlearn: 0.6438776\ttest: 0.6040530\tbest: 0.6041391 (1159)\ttotal: 3m 11s\tremaining: 7m 26s\n",
      "1300:\tlearn: 0.6475447\ttest: 0.6041056\tbest: 0.6043019 (1232)\ttotal: 3m 27s\tremaining: 7m 10s\n",
      "1400:\tlearn: 0.6511257\ttest: 0.6040530\tbest: 0.6043211 (1328)\ttotal: 3m 43s\tremaining: 6m 54s\n",
      "1500:\tlearn: 0.6548742\ttest: 0.6046801\tbest: 0.6047519 (1490)\ttotal: 3m 59s\tremaining: 6m 38s\n",
      "1600:\tlearn: 0.6583989\ttest: 0.6050248\tbest: 0.6050344 (1599)\ttotal: 4m 15s\tremaining: 6m 22s\n",
      "1700:\tlearn: 0.6621713\ttest: 0.6053025\tbest: 0.6053025 (1700)\ttotal: 4m 31s\tremaining: 6m 6s\n",
      "1800:\tlearn: 0.6656146\ttest: 0.6050966\tbest: 0.6053791 (1717)\ttotal: 4m 47s\tremaining: 5m 50s\n",
      "1900:\tlearn: 0.6692782\ttest: 0.6055131\tbest: 0.6055131 (1900)\ttotal: 5m 3s\tremaining: 5m 34s\n",
      "2000:\tlearn: 0.6725013\ttest: 0.6055418\tbest: 0.6056950 (1995)\ttotal: 5m 18s\tremaining: 5m 18s\n",
      "2100:\tlearn: 0.6757926\ttest: 0.6056855\tbest: 0.6057285 (2011)\ttotal: 5m 34s\tremaining: 5m 2s\n",
      "2200:\tlearn: 0.6796644\ttest: 0.6057956\tbest: 0.6058913 (2198)\ttotal: 5m 51s\tremaining: 4m 47s\n",
      "2300:\tlearn: 0.6834296\ttest: 0.6054987\tbest: 0.6059200 (2229)\ttotal: 6m 7s\tremaining: 4m 31s\n",
      "2400:\tlearn: 0.6867580\ttest: 0.6056902\tbest: 0.6059200 (2229)\ttotal: 6m 23s\tremaining: 4m 15s\n",
      "2500:\tlearn: 0.6899153\ttest: 0.6058769\tbest: 0.6059871 (2494)\ttotal: 6m 39s\tremaining: 3m 59s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-2123899f916b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0meval_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m )\n",
      "\u001b[0;32m/data/anaconda3/envs/torch1.8.1/lib/python3.6/site-packages/catboost/core.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, cat_features, text_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model)\u001b[0m\n\u001b[1;32m   3791\u001b[0m         self._fit(X, y, cat_features, text_features, None, sample_weight, None, None, None, None, baseline, use_best_model,\n\u001b[1;32m   3792\u001b[0m                   \u001b[0meval_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogging_level\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn_description\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_period\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3793\u001b[0;31m                   silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model)\n\u001b[0m\u001b[1;32m   3794\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3795\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/anaconda3/envs/torch1.8.1/lib/python3.6/site-packages/catboost/core.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, cat_features, text_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model)\u001b[0m\n\u001b[1;32m   1688\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1689\u001b[0m                 \u001b[0mallow_clear_pool\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1690\u001b[0;31m                 \u001b[0mtrain_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"init_model\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1691\u001b[0m             )\n\u001b[1;32m   1692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/anaconda3/envs/torch1.8.1/lib/python3.6/site-packages/catboost/core.py\u001b[0m in \u001b[0;36m_train\u001b[0;34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[0m\n\u001b[1;32m   1223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1224\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_clear_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1225\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_clear_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_object\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minit_model\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1226\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_trained_model_attributes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cbt.fit(\n",
    "    train_x, train_y,\n",
    "    eval_set=(valid_x, valid_y),\n",
    "    verbose=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## n2V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampling complete\n",
      "training\n",
      "training complete\n",
      "(3655452, 32)\n",
      "(3655452, 32)\n",
      "(3655452, 300)\n"
     ]
    }
   ],
   "source": [
    "print(\"sampling complete\")\n",
    "walks = walks.numpy().tolist()\n",
    "print(\"training\")\n",
    "model = Word2Vec(walks, vector_size=EMB_SIZE, window=10, min_count=0, sg=1, workers=12)\n",
    "print(\"training complete\")\n",
    "w2v = np.zeros([len(model.wv.index_to_key), EMB_SIZE])\n",
    "print(w2v.shape)\n",
    "for i, index_id in enumerate(sorted(model.wv.index_to_key)):\n",
    "    w2v[i] = model.wv[int(index_id)]\n",
    "\n",
    "with open(os.path.join(BASE_PATH, 'features_n2v.npy'), 'wb') as f:\n",
    "    np.save(f, w2v)\n",
    "\n",
    "print(w2v.shape)\n",
    "\n",
    "\n",
    "features = np.load(os.path.join(BASE_PATH, 'features.npy'))\n",
    "print(features.shape)\n",
    "features = np.hstack([features,w2v])\n",
    "with open(os.path.join(BASE_PATH, 'features_with_n2v.npy'), 'wb') as f:\n",
    "    np.save(f, features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
